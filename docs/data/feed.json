[
  {
    "id": "twitter_1989367049798463950",
    "source": "twitter",
    "author": "martin_ict_algo",
    "content": "@ben_vargas @HanifCarroll @FactoryAI Yeah true, It does feel like using factory models themselves does provide better integration/planning/execution than using like BYOK I have found, or at least using grok code fast and grok 4 fast, havent tried chatcpt as a BYOK yet.",
    "url": "https://x.com/martin_ict_algo/status/1989367049798463950",
    "timestamp": "2025-11-14T16:17:19.000Z",
    "metadata": {
      "conversation_id": "1989367049798463950",
      "likes": 0,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1989364869175685580",
    "source": "twitter",
    "author": "HanifCarroll",
    "content": "@martin_ict_algo @ben_vargas @FactoryAI Yep, exactly! But someone in another comment said that it Factory uses more tokens so you'll hit the rate limit more quickly. Something to keep in mind.",
    "url": "https://x.com/HanifCarroll/status/1989364869175685580",
    "timestamp": "2025-11-14T16:08:40.000Z",
    "metadata": {
      "conversation_id": "1989364869175685580",
      "likes": 1,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1989364860011118661",
    "source": "twitter",
    "author": "ben_vargas",
    "content": "@HanifCarroll @martin_ict_algo @FactoryAI Exactly... this setup allows using ChatGPT and Claude subscription use, but with the Factory/Droid harness - so not paying per token.\n\nTLDR; same reason you'd buy a sub vs use API key billing.",
    "url": "https://x.com/ben_vargas/status/1989364860011118661",
    "timestamp": "2025-11-14T16:08:37.000Z",
    "metadata": {
      "conversation_id": "1989364860011118661",
      "likes": 0,
      "retweets": 0,
      "replies": 1,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1989364571539402887",
    "source": "twitter",
    "author": "martin_ict_algo",
    "content": "@HanifCarroll @ben_vargas @FactoryAI Aah so you have a chatgpt $20 or so plan and use that but through droid?",
    "url": "https://x.com/martin_ict_algo/status/1989364571539402887",
    "timestamp": "2025-11-14T16:07:29.000Z",
    "metadata": {
      "conversation_id": "1989364571539402887",
      "likes": 1,
      "retweets": 0,
      "replies": 1,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1989363817952997447",
    "source": "twitter",
    "author": "HanifCarroll",
    "content": "@martin_ict_algo @ben_vargas @FactoryAI Token cost",
    "url": "https://x.com/HanifCarroll/status/1989363817952997447",
    "timestamp": "2025-11-14T16:04:29.000Z",
    "metadata": {
      "conversation_id": "1989363817952997447",
      "likes": 1,
      "retweets": 0,
      "replies": 2,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1989361124140322915",
    "source": "twitter",
    "author": "shreyas1009",
    "content": "@bentossell @itsbyrobin @FactoryAI Okay I read it! Makes sense now why a lot of users say it eats lots of tokens but also good at just getting it right most of the times.",
    "url": "https://x.com/shreyas1009/status/1989361124140322915",
    "timestamp": "2025-11-14T15:53:47.000Z",
    "metadata": {
      "conversation_id": "1989361124140322915",
      "likes": 0,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1989358641284256122",
    "source": "twitter",
    "author": "davidrsdlife",
    "content": "@LignoL23 @ben_vargas @FactoryAI ^ Not sure if it's the same with GPT 5.1 but the same happened to me with GPT 5 / Codex on Droid. Rather use the Codex extension and Sonnet 4.5 on Droid (via this same method) as the workflow because of that.",
    "url": "https://x.com/davidrsdlife/status/1989358641284256122",
    "timestamp": "2025-11-14T15:43:55.000Z",
    "metadata": {
      "conversation_id": "1989358641284256122",
      "likes": 0,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1989349830725173637",
    "source": "twitter",
    "author": "shreyas1009",
    "content": "@bentossell @itsbyrobin @FactoryAI Thanks will check it out!",
    "url": "https://x.com/shreyas1009/status/1989349830725173637",
    "timestamp": "2025-11-14T15:08:54.000Z",
    "metadata": {
      "conversation_id": "1989349830725173637",
      "likes": 0,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1989348010732757066",
    "source": "twitter",
    "author": "bentossell",
    "content": "@shreyas1009 @itsbyrobin @FactoryAI some info here: https://t.co/rQ3Jwmcklb\n\ngoing to get another blog post + doc page up",
    "url": "https://x.com/bentossell/status/1989348010732757066",
    "timestamp": "2025-11-14T15:01:40.000Z",
    "metadata": {
      "conversation_id": "1989348010732757066",
      "likes": 2,
      "retweets": 0,
      "replies": 2,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1989347642938392817",
    "source": "twitter",
    "author": "bentossell",
    "content": "@Ricardo_Nth @FactoryAI we handle the context for you though so you dont need to worry so much about that :)",
    "url": "https://x.com/bentossell/status/1989347642938392817",
    "timestamp": "2025-11-14T15:00:13.000Z",
    "metadata": {
      "conversation_id": "1989347642938392817",
      "likes": 1,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1989347551137653147",
    "source": "twitter",
    "author": "bentossell",
    "content": "@Ricardo_Nth @FactoryAI üî•",
    "url": "https://x.com/bentossell/status/1989347551137653147",
    "timestamp": "2025-11-14T14:59:51.000Z",
    "metadata": {
      "conversation_id": "1989347551137653147",
      "likes": 0,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1989347471269736702",
    "source": "twitter",
    "author": "nexiumship",
    "content": "@bentossell @FactoryAI Amazing! I think droid cis are the best and for the price for a team is why I‚Äôll be sticking around.",
    "url": "https://x.com/nexiumship/status/1989347471269736702",
    "timestamp": "2025-11-14T14:59:32.000Z",
    "metadata": {
      "conversation_id": "1989347471269736702",
      "likes": 0,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1989347391422824592",
    "source": "twitter",
    "author": "bentossell",
    "content": "@munoncode @ben_vargas @FactoryAI started having convos around this but nothing planned atm",
    "url": "https://x.com/bentossell/status/1989347391422824592",
    "timestamp": "2025-11-14T14:59:13.000Z",
    "metadata": {
      "conversation_id": "1989347391422824592",
      "likes": 2,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1989347150413922339",
    "source": "twitter",
    "author": "bentossell",
    "content": "@nexiumship @FactoryAI we have a new web product coming in the next few weeks",
    "url": "https://x.com/bentossell/status/1989347150413922339",
    "timestamp": "2025-11-14T14:58:15.000Z",
    "metadata": {
      "conversation_id": "1989347150413922339",
      "likes": 1,
      "retweets": 0,
      "replies": 1,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1989340430237143158",
    "source": "twitter",
    "author": "codewithimanshu",
    "content": "@CloudTrader4 @OpenAI @FactoryAI Right, Cloud, let's see how well GPT-5.1-Codex performs with FactoryAI; it'll be interesting to watch the results, no?",
    "url": "https://x.com/codewithimanshu/status/1989340430237143158",
    "timestamp": "2025-11-14T14:31:33.000Z",
    "metadata": {
      "conversation_id": "1989340430237143158",
      "likes": 0,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1989338868987133981",
    "source": "twitter",
    "author": "nexiumship",
    "content": "@FactoryAI I love droid trying to get agents on web to work as good as the CLI has been a challenge let me know any pointers.",
    "url": "https://x.com/nexiumship/status/1989338868987133981",
    "timestamp": "2025-11-14T14:25:21.000Z",
    "metadata": {
      "conversation_id": "1989338868987133981",
      "likes": 0,
      "retweets": 0,
      "replies": 1,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1989337847283769567",
    "source": "twitter",
    "author": "bentossell",
    "content": "@smithstephen @FactoryAI np. no our tokens dont roll-over unfortunately",
    "url": "https://x.com/bentossell/status/1989337847283769567",
    "timestamp": "2025-11-14T14:21:17.000Z",
    "metadata": {
      "conversation_id": "1989337847283769567",
      "likes": 0,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1989337620384825443",
    "source": "twitter",
    "author": "smithstephen",
    "content": "@bentossell @FactoryAI Ok thanks for letting me know so quickly - appreciate it. Outside of the free trial tokens - I hope that the paid ones will roll over (e.g. the way https://t.co/UYHKaFYojt rolls over unused credits).",
    "url": "https://x.com/smithstephen/status/1989337620384825443",
    "timestamp": "2025-11-14T14:20:23.000Z",
    "metadata": {
      "conversation_id": "1989337620384825443",
      "likes": 0,
      "retweets": 0,
      "replies": 1,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1989336030080844226",
    "source": "twitter",
    "author": "bentossell",
    "content": "@smithstephen @FactoryAI they dont roll over im afraid",
    "url": "https://x.com/bentossell/status/1989336030080844226",
    "timestamp": "2025-11-14T14:14:04.000Z",
    "metadata": {
      "conversation_id": "1989336030080844226",
      "likes": 0,
      "retweets": 0,
      "replies": 1,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1989334696602312801",
    "source": "twitter",
    "author": "smithstephen",
    "content": "@FactoryAI - I've got two more days left in my free trial and i've already set up billing for pro mode.  I've got a ton of tokens left in there.  Do they rollover (e.g. - does the $20/pro mode add 20M tokens to what I already have)? Or will they all disappear and I start with 20M fresh (hope not!) Thanks! @bentossell",
    "url": "https://x.com/smithstephen/status/1989334696602312801",
    "timestamp": "2025-11-14T14:08:46.000Z",
    "metadata": {
      "conversation_id": "1989334696602312801",
      "likes": 0,
      "retweets": 0,
      "replies": 1,
      "quotes": 0
    }
  },
  {
    "id": "reddit_1owv5gf",
    "source": "reddit",
    "author": "bentossell",
    "content": "how to set up custom models with Groq in &lt;1 min\n\nhttps://reddit.com/link/1owv5gf/video/vfpxccohu71g1/player\n\nvideo above  \ndocs: [https://docs.factory.ai/cli/byok/groq](https://docs.factory.ai/cli/byok/groq)",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1owv5gf/how_to_set_up_custom_models_with_groq_in_1_min/",
    "timestamp": "2025-11-14T12:27:05.000Z",
    "metadata": {
      "score": 1,
      "num_comments": 0,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "reddit_1owpdgs",
    "source": "reddit",
    "author": "Informal-Spinach-345",
    "content": "Todo list with minimax m2\n\nAny one else have issues with Minimax M2 on vllm not being able to properly use the todo list? \n\n  \nThis is what the output looks like, it eventually moves on but I never see a todo list:\n\n   Let me create a comprehensive todo list that captures all the remaining work.\n\n   &lt;/think&gt;\n\n\n\n\n\n\n\n\n\n‚õ¨  &lt;think&gt;I need to fix the todo format - the todos parameter should be an array, not an object.\n\n   &lt;/think&gt;\n\n\n\n\n\n\n\n\n\n‚õ¨  &lt;think&gt;Let me check the todo structure more carefully. Looking",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1owpdgs/todo_list_with_minimax_m2/",
    "timestamp": "2025-11-14T06:41:19.000Z",
    "metadata": {
      "score": 1,
      "num_comments": 6,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "reddit_1owbvoj",
    "source": "reddit",
    "author": "bentossell",
    "content": "How should we post changelogs here?\n\nhey, i'm ben - dev rel at factory. you may have seen me answering comments.\n\nwe have a changelog now but has like 4/5 updates a week. its automated as a bot in our discord channel. \n\nshould we add anything here? if so, what format is best?",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1owbvoj/how_should_we_post_changelogs_here/",
    "timestamp": "2025-11-13T20:22:54.000Z",
    "metadata": {
      "score": 6,
      "num_comments": 4,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "reddit_1ow4spq",
    "source": "reddit",
    "author": "Rough-Aioli-7829",
    "content": "Why I can't register my email?\n\nImages:\n\thttps://preview.redd.it/rgbm3fcdr11g1.png?auto=webp&amp;s=b0a9871d3d6836057ca15067a94c8a71463ae5ca\n",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1ow4spq/why_i_cant_register_my_email/",
    "timestamp": "2025-11-13T15:58:33.000Z",
    "metadata": {
      "score": 2,
      "num_comments": 1,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "reddit_1ow0203",
    "source": "reddit",
    "author": "vargalas",
    "content": "It's the worst onboarding experience ever\n\nThe provided cli instruction doesn't work, curl is complaining about self-signed certificate. The support link (after logging in) doesn't work. I tried to contact the sales on the homepage, but you cannot write them, they will contact. if they want. \n\nSo no Droid for me. I cannot see how they get customers. ",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1ow0203/its_the_worst_onboarding_experience_ever/",
    "timestamp": "2025-11-13T12:42:42.000Z",
    "metadata": {
      "score": 0,
      "num_comments": 2,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "github_issue_348",
    "source": "github",
    "author": "aranej",
    "content": "[Issue] üöÄ Feature Request: Native Task Queue Support for Interactive Mode\n\n## üìã Summary\n\nRequest for **native task queuing functionality** in Droid CLI interactive mode, allowing users to queue multiple prompts for sequential or parallel processing without waiting for each task to complete before submitting the next one.\n\n## üéØ Problem Statement\n\n### Current User Experience (Frustrating)\n\n```bash\n> /sys-info is running...\n[User types: /init-prompt]\n‚ùå Command doesn't register - must wait for completion\n\n[After 30 seconds...]\n‚úÖ /sys-info completed\n\n[User must now re-typ",
    "url": "https://github.com/Factory-AI/factory/issues/348",
    "timestamp": "2025-11-13T09:01:07Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 348
    }
  },
  {
    "id": "github_issue_345",
    "source": "github",
    "author": "xianzou",
    "content": "[Issue] Running dorid in PowerShell produces no output\n\n<img width=\"1113\" height=\"626\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/0bddc80a-404e-4fee-9575-96c0cdc89b94\" />\n\nRunning dorid in PowerShell produces no outputÔºåI have already installed dorid.",
    "url": "https://github.com/Factory-AI/factory/issues/345",
    "timestamp": "2025-11-13T01:46:56Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 345
    }
  },
  {
    "id": "reddit_1ovbn7q",
    "source": "reddit",
    "author": "UrAn8",
    "content": "Anyone having issues with the Bridge?\n\nLast few days bridge has been disconnecting frequently. then it started crashing after opening. Restarting cpu didn't help so I deleted the bridge, downloaded it again, restarted my computer, and now it's no longer crashing, but won't reconnect to any old or new sessions. Anyone else having this issue? ",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1ovbn7q/anyone_having_issues_with_the_bridge/",
    "timestamp": "2025-11-12T17:34:16.000Z",
    "metadata": {
      "score": 1,
      "num_comments": 3,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "github_issue_341",
    "source": "github",
    "author": "580ai",
    "content": "[Issue] droidÔºöIt seems that the maximum output tokens will not be outputted anymore once they reach 8192\n\nIt will suddenly terminate and then remain stuck without returning any content until the maximum timeout is reached",
    "url": "https://github.com/Factory-AI/factory/issues/341",
    "timestamp": "2025-11-12T08:46:22Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 341
    }
  },
  {
    "id": "github_issue_340",
    "source": "github",
    "author": "korallis",
    "content": "[Issue] Multi Agent Issues in regards to aggrigated RPC\n\n 1. Describe the behavior\n     ‚Ä¢  When you invoke multiple tools via the parallel wrapper, you get no output until every sub-task completes.\n     ‚Ä¢  If any sub-task fails, the entire batch is reported as failed even though the other tasks actually ran.\n\n   2. Explain why it‚Äôs a problem\n     ‚Ä¢  You can‚Äôt see partial results or errors in real time.\n     ‚Ä¢  One failing branch masks useful output from the others, slowing triage and forcing retries.\n\n   3. Request the remedy\n     ‚Ä¢  Ask for streaming",
    "url": "https://github.com/Factory-AI/factory/issues/340",
    "timestamp": "2025-11-11T17:16:42Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 340
    }
  },
  {
    "id": "github_issue_337",
    "source": "github",
    "author": "etwk",
    "content": "[Issue] Make Copy Smooth\n\nDroid UI looks nice, but when I try to copy text to a editor to work further on it, there are some formatting issues:\n  - Frequent un-intended line breaks\n  - Empty space before each lines\n\nCan we make the transaction more smooth? It'll be huge UX enhancement.",
    "url": "https://github.com/Factory-AI/factory/issues/337",
    "timestamp": "2025-11-10T23:07:38Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 337
    }
  },
  {
    "id": "github_issue_335",
    "source": "github",
    "author": "etwk",
    "content": "[Issue] Subagent No Output\n\nTesting some subagents with the builtin models, the subagents seems running well but the main process never gets the output from the subagent task.\n\nUsing latest Droid (0.22.14) with the GPT-5-Codex model, getting this result:\n```\nAttempted to invoke the available subagents (code-reviewer, debugger) with simple greeting prompts, but each Task call returned ‚ÄúNo output received from task subagent,‚Äù so the requested ‚Äúhi‚Äù response could not be produced.\n```",
    "url": "https://github.com/Factory-AI/factory/issues/335",
    "timestamp": "2025-11-10T12:55:34Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 335
    }
  },
  {
    "id": "github_issue_334",
    "source": "github",
    "author": "etwk",
    "content": "[Issue] droid exec will change default model for the main process\n\nCurrently droid exec will change default model for the main process, maybe we should change this partly because of convenience, and partly because of process separation, not letting 2 unrelated process interfering in any possible way.",
    "url": "https://github.com/Factory-AI/factory/issues/334",
    "timestamp": "2025-11-10T12:42:52Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 334
    }
  },
  {
    "id": "github_issue_331",
    "source": "github",
    "author": "spionkind",
    "content": "[Issue] Issue with GPT5 Codex and Custom Model on Droid\n\n Hi,\n\nwhenever I chosed GPT5-codex model it show this error message:\nError: 400 Invalid 'tools[40].name': string too long. Expected a string with maximum length 64, but got a string with length 66 instead.\n\nand when I try with custom model (qwen3 coder), it shows this:\nError: 400 <400> InternalError.Algo.InvalidParameter: The length of the tool name cannot exceed 64.\n\nDroid still works well with other model suchas sonnet 4.5, glm 4.6\n\nPlease help me on this issues\n\nBest regards,\nGiang",
    "url": "https://github.com/Factory-AI/factory/issues/331",
    "timestamp": "2025-11-09T16:19:30Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 331
    }
  },
  {
    "id": "github_issue_330",
    "source": "github",
    "author": "olsavmic",
    "content": "[Issue] Feature Request: Implement Statusline Support\n\n  Add support for customizable statuslines in Factory's CLI interface, as documented in [Claude Code's statusline\n  feature](https://code.claude.com/docs/en/statusline).\n\n  Motivation\n\n  Statuslines provide persistent contextual information at the bottom of the interface, which is incredibly helpful for:\n   ‚Ä¢  Git awareness: Immediately see the current branch without running git status\n   ‚Ä¢  Directory context: Know your current working directory at a glance\n   ‚Ä¢  Session info: Display the curren",
    "url": "https://github.com/Factory-AI/factory/issues/330",
    "timestamp": "2025-11-09T11:34:21Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 330
    }
  },
  {
    "id": "reddit_1osf7sj",
    "source": "reddit",
    "author": "LittleChallenge8717",
    "content": "Custom Droid | Web search Task failed\n\nWeb search and calling custom droid feature in Droid not working, I use claude code inside droid (with CLIProxyAPI),\n\n(Neither works on openrouter models)\n\n\"\n\nWEB SEARCH  (\"current bitcoin price BTC USD\")\n\nSearch failed: Error: Error performing web search: Fetch failed\n\nWEB SEARCH  (\"ethereum ETH price USD current\")\n\nSearch failed: Error: Error performing web search: Fetch failed\n\n\"\n\n\" TASK  (mermaid-expert: \"Create system architecture diagram\")\n\n‚ö† Task failed\n\nTASK  (seo-meta-optimizer: \"Optimi",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1osf7sj/custom_droid_web_search_task_failed/",
    "timestamp": "2025-11-09T09:35:38.000Z",
    "metadata": {
      "score": 3,
      "num_comments": 3,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "github_issue_329",
    "source": "github",
    "author": "TheSingular",
    "content": "[Issue] Spec mode hides reasoning level effort in model name\n\nWhen using the spec mode, you cannot see the reasoning effort of the model you have selected (if it supports reasoning).\nYou can still change the reasoning effort via the tab key, but you cannot see its effect at all. Other modes properly display the reasoning effort in parentheses.\n\nHow to reproduce:\n1. Use model Sonnet 4.5 with low reasoning effort, do not choose a separate model for the spec model.\n2. Toggle to spec mode via ctrl + t.\n3. Observe the parentheses containing the reasoning effort",
    "url": "https://github.com/Factory-AI/factory/issues/329",
    "timestamp": "2025-11-09T09:12:43Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 329
    }
  },
  {
    "id": "github_issue_328",
    "source": "github",
    "author": "a112121788",
    "content": "[Issue] custom model support reasoning\n\n",
    "url": "https://github.com/Factory-AI/factory/issues/328",
    "timestamp": "2025-11-08T15:47:20Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 328
    }
  },
  {
    "id": "github_issue_325",
    "source": "github",
    "author": "Evan-Kim2028",
    "content": "[Issue] Task subagent runs tools but returns no final message (intermittent)\n\nSummary\n- Intermittently, Task executions succeed and run tools (Grep/Read/Glob/TodoWrite) but no final assistant message is emitted, and the wrapper surfaces: \"No output received from task subagent.\" This blocks using dbt droids for reviews.\n\nEnvironment\n- OS: macOS darwin 24.6.0\n- Factory CLI/session: latest as of 2025-11-07\n- Model: OpenAI GPT-5\n- gh: 2.80.0\n\nReproduction (today)\n1) Launch Task with subagent_type=\"dbt-quality-droid\" on local repo /Users/evandekim/Documents/spellbook (branch: ",
    "url": "https://github.com/Factory-AI/factory/issues/325",
    "timestamp": "2025-11-07T21:38:02Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 325
    }
  },
  {
    "id": "reddit_1or5cow",
    "source": "reddit",
    "author": "Durst123",
    "content": "What are the weekly limits in droid CLI?\n\nComparing it to Claude max.\n\nI hit the limits.",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1or5cow/what_are_the_weekly_limits_in_droid_cli/",
    "timestamp": "2025-11-07T20:29:10.000Z",
    "metadata": {
      "score": 1,
      "num_comments": 6,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "github_issue_321",
    "source": "github",
    "author": "nilzzzzzz",
    "content": "[Issue] Droid exec --output-format debug is not returning the result\n\nWe rely heavily on `droid exec` but since one of the last updates there is a huge issue. Running `droid exec --output-format debug` does not return anymore the result but just the debug outputs before:\n\nReproduction:\n\n```\ndroid exec \"which services does the backend have\" --output-format debug\n\n{\"type\":\"system\",\"subtype\":\"init\",\"cwd\":\"/Users/nilz/Repositories/awork-backend\",\"session_id\":\"273c1ae2-ffec-4ef5-b748-e04d713000fa\",\"tools\":[\"Read\",\"LS\",\"Execute\",\"Edit\",\"ApplyPatch\",\"Grep\",\"Glob\",\"Create",
    "url": "https://github.com/Factory-AI/factory/issues/321",
    "timestamp": "2025-11-07T12:11:44Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 321
    }
  },
  {
    "id": "github_issue_319",
    "source": "github",
    "author": "Bladed3d",
    "content": "[Issue] \"Endless Processing\" When using custom model openrouter: Grok-Code-Fast-1\n\nWhen using custom model openrouter: Grok-Code-Fast-1 after giving it a task, Droid will keep working on that until I press ESC then display context it has been building up. Upon further review, it seems that Droid using Grok is having a conversation with itself, forgetting to include me and wait for my actual participation:\n\n(This is just some of the context...)\n\nConfirming Dashboard Functionality\n   ‚Ä¢  The dashboard no longer shows duplicates, displaying only the current session's 1\n      root ",
    "url": "https://github.com/Factory-AI/factory/issues/319",
    "timestamp": "2025-11-06T20:19:04Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 319
    }
  },
  {
    "id": "reddit_1op6njm",
    "source": "reddit",
    "author": "Sakrilegi0us",
    "content": "Droid is failing to compress every time and I have to start a new chat.\n\nI keep getting \"Error: stream ended without producing a Message with role=assistant\" when reach my context window and It fails to compress every time. Im using vibeProxy to use my claude code max subscription and switching model, or service (to codex or GLM) I get \"Error: Failed to compress conversation for model switch\"",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1op6njm/droid_is_failing_to_compress_every_time_and_i/",
    "timestamp": "2025-11-05T15:57:27.000Z",
    "metadata": {
      "score": 5,
      "num_comments": 15,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "reddit_1oomptx",
    "source": "reddit",
    "author": "samplifyk",
    "content": "Factory agents running locally or cloud triggered by linear tickets\n\nHas anyone managed to achieve this?",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1oomptx/factory_agents_running_locally_or_cloud_triggered/",
    "timestamp": "2025-11-04T23:17:50.000Z",
    "metadata": {
      "score": 1,
      "num_comments": 2,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "github_issue_314",
    "source": "github",
    "author": "lifeisnphard",
    "content": "[Issue] File selector '@' not working in iTerm2\n\n## Environment\n- **OS**: macOS (darwin 25.0.0)\n- **Terminal**: iTerm2\n- **Factory CLI**: (version needs verification)\n- **Date**: 2025-11-04\n\n## Issue Description\nThe file selector feature triggered by the `@` symbol is not working in iTerm2. This functionality works correctly in Warp terminal but fails to appear in iTerm2.\n\n## Expected Behavior\nWhen typing `@` in the Factory Droid CLI interface, a file selector/picker UI should appear to allow interactive file selection, similar to the behavior",
    "url": "https://github.com/Factory-AI/factory/issues/314",
    "timestamp": "2025-11-04T19:12:02Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 314
    }
  },
  {
    "id": "github_discussion_309",
    "source": "github",
    "author": "msneijders",
    "content": "[Discussion] Droid CLI: configurable timeouts per mcp server\n\n**Motivation**: I use a 'Language Server Protocol' mcp for adding tools to query symbols and find_usage and such. But on large projects and during first-time use they can take quite some time before giving responses; causing timeouts in droid cli. If I could configure a larger timeout for this specific mcp server it could work better.",
    "url": "https://github.com/Factory-AI/factory/discussions/309",
    "timestamp": "2025-11-04T10:48:14Z",
    "metadata": {
      "type": "discussion",
      "category": "Feature requests",
      "number": 309
    }
  },
  {
    "id": "github_issue_308",
    "source": "github",
    "author": "Evan-Kim2028",
    "content": "[Issue] MCP servers configured globally aren‚Äôt exposed inside custom droid sessions (tools work in main interface, fail inside droid)\n\n## Summary\nMCP servers (dbt-mcp, igloo-mcp, github-mcp) are configured globally and work in the main interface, but their tools are not available when running inside a custom droid session. As a result, dbt/igloo/github MCP tool calls succeed outside the droid but fail inside the droid with messages indicating no MCP interface/tools.\n\n## Environment\n- OS: macOS 14.6 (24.6.0)\n- Shell: droid CLI (interactive)\n- Custom droid: `dbt_quality_droid` (personal droid)\n- MCP: servers registered globally (",
    "url": "https://github.com/Factory-AI/factory/issues/308",
    "timestamp": "2025-11-03T20:08:35Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 308
    }
  },
  {
    "id": "github_issue_301",
    "source": "github",
    "author": "nusquama",
    "content": "[Issue] How to configure Azure OpenAI with Factory CLI?\n\n\n\nHi\n\nI'm trying to configure Azure OpenAI (GPT-5 Codex) with Factory CLI using BYOK, but I can't find any documentation on how to properly set this up.\n\nI saw in the [[CLI Updates changelog](https://docs.factory.ai/changelog/cli-updates)](https://docs.factory.ai/changelog/cli-updates) that \"Azure OpenAI for GPT-5\" support was added, but there's no example configuration in the [[BYOK documentation](https://docs.factory.ai/cli/byok/overview)](https://docs.factory.ai/cli/byok/overview).\n\n**What I ",
    "url": "https://github.com/Factory-AI/factory/issues/301",
    "timestamp": "2025-11-02T10:10:24Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 301
    }
  },
  {
    "id": "github_issue_300",
    "source": "github",
    "author": "dpalfery",
    "content": "[Issue] Can't use standard c:\\git for root directory on windows\n\nFactory Bridge assumes that all windows developers put the git repos in c:\\users\\<user> but this is very rarely the case wtih expereinced professional developers. we use c:\\git or similar just as mac devs use \\home\\git . need to be able to change this with out adding a link.",
    "url": "https://github.com/Factory-AI/factory/issues/300",
    "timestamp": "2025-11-02T02:47:51Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 300
    }
  },
  {
    "id": "github_issue_298",
    "source": "github",
    "author": "tgerighty",
    "content": "[Issue] bug: droids using custom model with same name as a built-in model use the built-in model\n\nI have a number of droids defined and they all use the custom model defined in the droid. However, instead of using the custom model, they're being remapped to use the factory built-in model instead. This happens when your custom model has the same name as a factory model, which in my case I want to use my GLM-4.6 account with z.ai rather than using the factory model. \n\n**1. Droid Configuration Evidence (Custom Models Defined):**\n\ndroids/code-reviewer-droid-forge.md`\n\n   yaml\n     ---\n     name:",
    "url": "https://github.com/Factory-AI/factory/issues/298",
    "timestamp": "2025-11-01T16:36:44Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 298
    }
  },
  {
    "id": "github_issue_292",
    "source": "github",
    "author": "krit3dvanced",
    "content": "[Issue] How to select branch other than main in web?\n\nI want to create a document of my project (dev branch) using knowledge droid.\nBut I cannot find a menu to switch branch from `main` to `dev` branch",
    "url": "https://github.com/Factory-AI/factory/issues/292",
    "timestamp": "2025-10-31T09:00:34Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 292
    }
  },
  {
    "id": "github_discussion_240",
    "source": "github",
    "author": "factory-ben",
    "content": "[Discussion] Mini Changelog\n\n<img width=\"686\" height=\"397\" alt=\"Screenshot 2025-10-22 at 14 58 16\" src=\"https://github.com/user-attachments/assets/0288d87c-55b1-44b4-91cb-33d745fc052b\" />\r\n",
    "url": "https://github.com/Factory-AI/factory/discussions/240",
    "timestamp": "2025-10-23T09:45:14Z",
    "metadata": {
      "type": "discussion",
      "category": "Factory Official",
      "number": 240
    }
  },
  {
    "id": "github_discussion_225",
    "source": "github",
    "author": "JohnDotOwl",
    "content": "[Discussion] Change Log\n\nCan we have more updated change logs somewhere if possible. \r\n\r\nSuccessfully updated to version 0.21.5 Just saw this ",
    "url": "https://github.com/Factory-AI/factory/discussions/225",
    "timestamp": "2025-10-21T09:52:33Z",
    "metadata": {
      "type": "discussion",
      "category": "Feature requests",
      "number": 225
    }
  },
  {
    "id": "github_discussion_223",
    "source": "github",
    "author": "JohnDotOwl",
    "content": "[Discussion] [Discussion] Droid Exec Headless Streaming with output format (JSON)\n\nDroid Exec (Headless)\r\nIt make sense to use --output-format json if you're running a headless droid exec as that's the best way to programmatically manage the headless droid. The issue for me is i can't see the process and potentially stop it without --output-format debug and i can't run both output format. \r\n\r\nShould we consider having a different parameter for \"streaming\" , it's not so much for debugging but more to manage the task itself. ",
    "url": "https://github.com/Factory-AI/factory/discussions/223",
    "timestamp": "2025-10-21T02:46:01Z",
    "metadata": {
      "type": "discussion",
      "category": "Feature requests",
      "number": 223
    }
  },
  {
    "id": "github_discussion_214",
    "source": "github",
    "author": "0xStuart",
    "content": "[Discussion] JetBrains Plugin\n\nThe documentation says there is a JetBrains Plugin in the marketplace, but I can't find it.",
    "url": "https://github.com/Factory-AI/factory/discussions/214",
    "timestamp": "2025-10-19T19:55:35Z",
    "metadata": {
      "type": "discussion",
      "category": "Questions",
      "number": 214
    }
  },
  {
    "id": "github_discussion_164",
    "source": "github",
    "author": "tgerighty",
    "content": "[Discussion] Droid Exec - custom models supported?\n\ncan we have support for custom models in droid exec? even if it were just simple endpoint/key.",
    "url": "https://github.com/Factory-AI/factory/discussions/164",
    "timestamp": "2025-10-10T18:34:32Z",
    "metadata": {
      "type": "discussion",
      "category": "Feature requests",
      "number": 164
    }
  },
  {
    "id": "github_discussion_151",
    "source": "github",
    "author": "snowarch",
    "content": "[Discussion] Sound or notification when completed task\n\nIt would be useful to have some kind of sound or notification in the system when the agent has completed the task. Droid CLI, Arch Linux.",
    "url": "https://github.com/Factory-AI/factory/discussions/151",
    "timestamp": "2025-10-09T10:20:14Z",
    "metadata": {
      "type": "discussion",
      "category": "Feature requests",
      "number": 151
    }
  },
  {
    "id": "github_discussion_108",
    "source": "github",
    "author": "factory-ben",
    "content": "[Discussion] Release v1.3.220\n\n---\r\n\r\nThis release brings HTTP MCP server support, a `/compress` command to optimize your context usage and droid exec for CDE.\r\n\r\n---\r\n\r\n## HTTP MCP Server Support\r\n\r\nFactory now supports streamable HTTP-based Model Context Protocol (MCP) servers in addition to stdio-based servers. This enables you to connect to MCP servers running as web services, making it easier to integrate with cloud-hosted tools and services.\r\n\r\nWhen adding an MCP server, Factory automatically detects whether it's HTTP o",
    "url": "https://github.com/Factory-AI/factory/discussions/108",
    "timestamp": "2025-10-03T20:21:56Z",
    "metadata": {
      "type": "discussion",
      "category": "Factory Official",
      "number": 108
    }
  },
  {
    "id": "github_discussion_99",
    "source": "github",
    "author": "Evan-Kim2028",
    "content": "[Discussion] Droid source code\n\nIs droid closed source? I am not able to find any code. I would like to be able to see how the droid tools are implemented if the code is available to see",
    "url": "https://github.com/Factory-AI/factory/discussions/99",
    "timestamp": "2025-10-02T17:51:27Z",
    "metadata": {
      "type": "discussion",
      "category": "Questions",
      "number": 99
    }
  },
  {
    "id": "github_discussion_95",
    "source": "github",
    "author": "factory-ben",
    "content": "[Discussion] CLI v0.16.0 Release Notes\n\n- Sonnet 4.5 model is now available\r\n- Clear chat input using double ESC or Ctrl-C\r\n- User-configured allow and deny list of commands to execute\r\n- Option to disable droid commit co-authoring\r\n- Auth using FACTORY_API_KEY\r\n- Fixed UI bugs due to resizing",
    "url": "https://github.com/Factory-AI/factory/discussions/95",
    "timestamp": "2025-10-01T20:05:01Z",
    "metadata": {
      "type": "discussion",
      "category": "Factory Official",
      "number": 95
    }
  },
  {
    "id": "github_discussion_92",
    "source": "github",
    "author": "msneijders",
    "content": "[Discussion] MCP tools filtering\n\nI would like to configure exactly what tools of a MCP server should be made available.\r\n\r\nMotivation: MCP servers with overlapping functionality and too many unneeded tools is confusing the models.",
    "url": "https://github.com/Factory-AI/factory/discussions/92",
    "timestamp": "2025-10-01T09:07:33Z",
    "metadata": {
      "type": "discussion",
      "category": "Feature requests",
      "number": 92
    }
  },
  {
    "id": "github_discussion_82",
    "source": "github",
    "author": "mweichert",
    "content": "[Discussion] Web API?\n\nHi there! Is there a web API to create and manage sessions?",
    "url": "https://github.com/Factory-AI/factory/discussions/82",
    "timestamp": "2025-09-29T13:16:25Z",
    "metadata": {
      "type": "discussion",
      "category": "Questions",
      "number": 82
    }
  },
  {
    "id": "github_discussion_72",
    "source": "github",
    "author": "rubendn",
    "content": "[Discussion] Droid selection in CLI?\n\nIs there a way to use one of the specialized Droids (Product, Tutorial, etc) via the CLI?  I don't see a way to select in the slash commands.\r\n\r\nAlso, is there a way on Windows to select a local workspace path besides ~\\?\r\n\r\nThanks!",
    "url": "https://github.com/Factory-AI/factory/discussions/72",
    "timestamp": "2025-09-29T05:17:49Z",
    "metadata": {
      "type": "discussion",
      "category": "Questions",
      "number": 72
    }
  },
  {
    "id": "github_discussion_66",
    "source": "github",
    "author": "factory-ben",
    "content": "[Discussion] 2 new community builds: use claude/codex max subscriptions with droid\n\n- [Factory CLI with ChatGPT Codex / Claude subscription via CLIProxyAPI](https://gist.github.com/chandika/c4b64c5b8f5e29f6112021d46c159fdd) - Guide to run Factory CLI against Claude Code Max or ChatGPT Codex through CLIProxyAPI by [chandika](https://github.com/chandika)\r\n- [Factory CLI with Claude subscription via CLIProxyAPI](https://gist.github.com/ben-vargas/9f1a14ac5f78d10eba56be437b7c76e5) - Setup instructions for using Factory CLI with Claude Code Max through CLIProxyAPI by [ben-vargas](ht",
    "url": "https://github.com/Factory-AI/factory/discussions/66",
    "timestamp": "2025-09-27T19:15:40Z",
    "metadata": {
      "type": "discussion",
      "category": "Show + tell",
      "number": 66
    }
  },
  {
    "id": "github_discussion_65",
    "source": "github",
    "author": "jimkyndemeyer",
    "content": "[Discussion] BYOK with Anthropic models on Amazon Bedrock\n\nWould be great to have the option of using Amazon Bedrock for Anthropic models with BYOK.\r\n\r\nAnthropic has official SDKs for Bedrock, but the model env config is a bit different:\r\n- AWS region\r\n- Access key id\r\n- Secret access key",
    "url": "https://github.com/Factory-AI/factory/discussions/65",
    "timestamp": "2025-09-27T09:46:55Z",
    "metadata": {
      "type": "discussion",
      "category": "Feature requests",
      "number": 65
    }
  },
  {
    "id": "github_discussion_59",
    "source": "github",
    "author": "factory-ben",
    "content": "[Discussion] #1 on Terminal Bench\n\n<img width=\"1582\" height=\"972\" alt=\"Screenshot 2025-09-25 at 17 15 56\" src=\"https://github.com/user-attachments/assets/9e9c80b6-825c-41cc-b8c7-236b21e3f61c\" />\r\n\r\nRead how we did it: https://factory.ai/news/terminal-bench",
    "url": "https://github.com/Factory-AI/factory/discussions/59",
    "timestamp": "2025-09-25T19:22:25Z",
    "metadata": {
      "type": "discussion",
      "category": "Factory Official",
      "number": 59
    }
  },
  {
    "id": "github_discussion_32",
    "source": "github",
    "author": "factory-ben",
    "content": "[Discussion] CLI v0.7.0 Release Notes\n\nCLI Release (0.7.0)\r\n\r\n- Autonomy level selection: Users can now select any preferred autonomy level when confirming the ExitSpec tool\r\n- Claude reasoning support: Added support for Claude's reasoning capabilities\r\n- Session resumption: Users can now resume existing sessions when operating in Exec Mode\r\n- Image reading capabilities: The CLI can now read and process images",
    "url": "https://github.com/Factory-AI/factory/discussions/32",
    "timestamp": "2025-09-19T20:15:48Z",
    "metadata": {
      "type": "discussion",
      "category": "Factory Official",
      "number": 32
    }
  },
  {
    "id": "github_discussion_25",
    "source": "github",
    "author": "DannyAziz",
    "content": "[Discussion] Change model even if I've already written a prompt out\n\nSometimes I write a message, then realise I want to drop down to Sonnet, and I have to delete my message to hit the slash command. I wish there was a way to do this without deleting everything.",
    "url": "https://github.com/Factory-AI/factory/discussions/25",
    "timestamp": "2025-09-16T22:58:36Z",
    "metadata": {
      "type": "discussion",
      "category": "Feature requests",
      "number": 25
    }
  },
  {
    "id": "github_discussion_20",
    "source": "github",
    "author": "factory-ben",
    "content": "[Discussion] CLI v0.5.0 Release Notes\n\nv0.5 release:\r\n\r\n- Users can now queue messages while the Droid works\r\n- Added clearer autonomy level & mode descriptions\r\n- Fixed many flickering issues\r\n- Revamped `--help` command\r\n- Automatic VSCode / Cursor / Windsurf CLI detection,\r\n- Windows delete key bug fixed\r\n- Lots of small UI improvements\r\n- Lots of quality of life and bug fixes\n\ncoming soon:\n- custom droids/subagents\n- notif sounds\n- much more\n\nany requests? ",
    "url": "https://github.com/Factory-AI/factory/discussions/20",
    "timestamp": "2025-09-16T06:27:29Z",
    "metadata": {
      "type": "discussion",
      "category": "Factory Official",
      "number": 20
    }
  },
  {
    "id": "github_discussion_19",
    "source": "github",
    "author": "fredrivett",
    "content": "[Discussion] Hacked a lil hit counter for my site in a day w/ droid\n\nThe man @bentossell gave me access to droid last week, and I had the urge to add a retro hit counter to my site, so it was the perfect opportunity to test it out.\r\n\r\nBy the evening I'd gone back and forth on the tech, built it out and deployed it, with the widget live [on my site](https://www.fredrivett.com/).\r\n\r\nIt's live here: https://www.herenow.fyi/\r\nAnd I've since split out the core code into this open source repo so anyone can set their own up: https://github.com/fredrivett/here-now\r\n\r\nFee",
    "url": "https://github.com/Factory-AI/factory/discussions/19",
    "timestamp": "2025-09-15T20:42:07Z",
    "metadata": {
      "type": "discussion",
      "category": "Show + tell",
      "number": 19
    }
  }
]