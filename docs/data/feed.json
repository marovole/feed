[
  {
    "id": "twitter_1990524414430228941",
    "source": "twitter",
    "author": "mudassir_siddi",
    "content": "Kylan, love the 2-reviewer rule with Droid and Codex, keeps things tight without endless loops. We've got something similar in Hikaflow for PRs plus post-merge impact scans to flag regressions early. Fits your 'rinse and repeat' vibe? \nWould be fun to compare setups: https://t.co/hICfvFSkqx",
    "url": "https://x.com/mudassir_siddi/status/1990524414430228941",
    "timestamp": "2025-11-17T20:56:17.000Z",
    "metadata": {
      "conversation_id": "1990524414430228941",
      "likes": 0,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1990518267719660008",
    "source": "twitter",
    "author": "duru_tobe",
    "content": "@explosivesox @FactoryAI @getdomeapi @openservai @Polymarket @hash_dive less noise, more action",
    "url": "https://x.com/duru_tobe/status/1990518267719660008",
    "timestamp": "2025-11-17T20:31:51.000Z",
    "metadata": {
      "conversation_id": "1990518267719660008",
      "likes": 0,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1990505496110117166",
    "source": "twitter",
    "author": "fred_pope",
    "content": "@melodykoh @AnthropicAI @FactoryAI @every Here you go @melodykoh ... this what all started it for me. \n\nhttps://t.co/sHIhrzxe8g\n\nIf you want to see more examples.... I can get on a call with you and help you out.\n\nLike IRL... we're all still figuring it out!",
    "url": "https://x.com/fred_pope/status/1990505496110117166",
    "timestamp": "2025-11-17T19:41:06.000Z",
    "metadata": {
      "conversation_id": "1990505496110117166",
      "likes": 0,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1990505045037600959",
    "source": "twitter",
    "author": "stanleyimet",
    "content": "Wanted to try using @FactoryAI \nFirst, it gave an error after linking my card, and as a result, I couldn't receive 10M bonus tokens. Okay, so I decided to try with at least 1M. But on the very first request, I got this error. And the funny thing is, I spent 262k tokens on it! https://t.co/m5GkZxPZG9",
    "url": "https://x.com/stanleyimet/status/1990505045037600959",
    "timestamp": "2025-11-17T19:39:19.000Z",
    "metadata": {
      "conversation_id": "1990505045037600959",
      "likes": 0,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1990496556836139285",
    "source": "twitter",
    "author": "ain3sh",
    "content": "@EnoReyes @CloudTrader4 @FactoryAI Thx!! Yeah that‚Äôs what Anthropic does too but I really got sick of telling Claude explicitly to use a skill bc that just goes against my mental model of how an agent should be leveraging skills lol. Did y‚Äôall do your progressive disclosure any differently?",
    "url": "https://x.com/ain3sh/status/1990496556836139285",
    "timestamp": "2025-11-17T19:05:35.000Z",
    "metadata": {
      "conversation_id": "1990496556836139285",
      "likes": 0,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1990495663759753486",
    "source": "twitter",
    "author": "EnoReyes",
    "content": "@ain3sh @CloudTrader4 @FactoryAI Super interesting! it's more of a proactive skill loading situation. Our implementation basically loads the skills available at droid start (as a tool description)",
    "url": "https://x.com/EnoReyes/status/1990495663759753486",
    "timestamp": "2025-11-17T19:02:02.000Z",
    "metadata": {
      "conversation_id": "1990495663759753486",
      "likes": 1,
      "retweets": 0,
      "replies": 1,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1990489680358621392",
    "source": "twitter",
    "author": "jonnydahorse",
    "content": "@explosivesox @FactoryAI @getdomeapi @openservai @Polymarket @hash_dive Hope to see more of your work with @openservai  soon?",
    "url": "https://x.com/jonnydahorse/status/1990489680358621392",
    "timestamp": "2025-11-17T18:38:15.000Z",
    "metadata": {
      "conversation_id": "1990489680358621392",
      "likes": 1,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1990489136927814060",
    "source": "twitter",
    "author": "explosivesox",
    "content": "@jonnydahorse @FactoryAI @getdomeapi @openservai @Polymarket @hash_dive Thank you Johny :)\n\nThis is the warm up.",
    "url": "https://x.com/explosivesox/status/1990489136927814060",
    "timestamp": "2025-11-17T18:36:06.000Z",
    "metadata": {
      "conversation_id": "1990489136927814060",
      "likes": 1,
      "retweets": 0,
      "replies": 1,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1990487298417569961",
    "source": "twitter",
    "author": "jonnydahorse",
    "content": "@explosivesox @FactoryAI @getdomeapi @openservai @Polymarket @hash_dive Insanely clean build this is the kind of stack that actually moves the space forward üöÄ\nThe speed the infra the partnerships everything screams real execution\nIf this is v1 the next waves are going to hit like a truck\nMassive respect this is seriously well built üî•",
    "url": "https://x.com/jonnydahorse/status/1990487298417569961",
    "timestamp": "2025-11-17T18:28:48.000Z",
    "metadata": {
      "conversation_id": "1990487298417569961",
      "likes": 1,
      "retweets": 0,
      "replies": 1,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1990486571364311061",
    "source": "twitter",
    "author": "ain3sh",
    "content": "@EnoReyes @CloudTrader4 @FactoryAI @EnoReyes any feedback/thoughts on my attempt? Wanted to purposely deviate from Anthropic‚Äôs strategy for actually motivating the model to load and use the skills while staying compatible :)\n\nhttps://t.co/7ZwvFouVFD",
    "url": "https://x.com/ain3sh/status/1990486571364311061",
    "timestamp": "2025-11-17T18:25:54.000Z",
    "metadata": {
      "conversation_id": "1990486571364311061",
      "likes": 0,
      "retweets": 0,
      "replies": 1,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1990475533323288657",
    "source": "twitter",
    "author": "kllrbeez",
    "content": "@explosivesox @FactoryAI @getdomeapi @openservai @Polymarket @hash_dive Big! $serv rooting!",
    "url": "https://x.com/kllrbeez/status/1990475533323288657",
    "timestamp": "2025-11-17T17:42:03.000Z",
    "metadata": {
      "conversation_id": "1990475533323288657",
      "likes": 2,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1990472700071194919",
    "source": "twitter",
    "author": "steipete",
    "content": "@BillCrosby @FactoryAI ü´∂",
    "url": "https://x.com/steipete/status/1990472700071194919",
    "timestamp": "2025-11-17T17:30:47.000Z",
    "metadata": {
      "conversation_id": "1990472700071194919",
      "likes": 1,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1990472083252412787",
    "source": "twitter",
    "author": "captaink99",
    "content": "@thdxr That‚Äôs looks neat.  @FactoryAI",
    "url": "https://x.com/captaink99/status/1990472083252412787",
    "timestamp": "2025-11-17T17:28:20.000Z",
    "metadata": {
      "conversation_id": "1990472083252412787",
      "likes": 1,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1990469645221179423",
    "source": "twitter",
    "author": "GrumpyFreud",
    "content": "@explosivesox @lordr_eth @FactoryAI @getdomeapi @openservai @Polymarket @hash_dive https://t.co/JndjOLopGZ",
    "url": "https://x.com/GrumpyFreud/status/1990469645221179423",
    "timestamp": "2025-11-17T17:18:39.000Z",
    "metadata": {
      "conversation_id": "1990469645221179423",
      "likes": 2,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1990453668798492720",
    "source": "twitter",
    "author": "bentossell",
    "content": "@samuel_spitz @FactoryAI",
    "url": "https://x.com/bentossell/status/1990453668798492720",
    "timestamp": "2025-11-17T16:15:10.000Z",
    "metadata": {
      "conversation_id": "1990453668798492720",
      "likes": 1,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1990453078663835999",
    "source": "twitter",
    "author": "melodykoh",
    "content": "@fred_pope @AnthropicAI @FactoryAI @every Ah makes sense. Have to take a look at hooks",
    "url": "https://x.com/melodykoh/status/1990453078663835999",
    "timestamp": "2025-11-17T16:12:49.000Z",
    "metadata": {
      "conversation_id": "1990453078663835999",
      "likes": 0,
      "retweets": 0,
      "replies": 1,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1990443927267357015",
    "source": "twitter",
    "author": "pascallammers_",
    "content": "@DeaNHtiD99 Droid from @FactoryAI",
    "url": "https://x.com/pascallammers_/status/1990443927267357015",
    "timestamp": "2025-11-17T15:36:27.000Z",
    "metadata": {
      "conversation_id": "1990443927267357015",
      "likes": 2,
      "retweets": 0,
      "replies": 1,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1990434622681825358",
    "source": "twitter",
    "author": "CyberBoyAyush",
    "content": "@FHulayyil @FactoryAI @greptile Try using gpt 5.1 high for plan\nAnd any other model to implement.\n\nYou will see a huge improvement",
    "url": "https://x.com/CyberBoyAyush/status/1990434622681825358",
    "timestamp": "2025-11-17T14:59:29.000Z",
    "metadata": {
      "conversation_id": "1990434622681825358",
      "likes": 0,
      "retweets": 0,
      "replies": 1,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1990429746333725147",
    "source": "twitter",
    "author": "fred_pope",
    "content": "@melodykoh @AnthropicAI @FactoryAI @every Skills are like context on demand. Hooks trigger them",
    "url": "https://x.com/fred_pope/status/1990429746333725147",
    "timestamp": "2025-11-17T14:40:06.000Z",
    "metadata": {
      "conversation_id": "1990429746333725147",
      "likes": 0,
      "retweets": 0,
      "replies": 1,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1990422509913579561",
    "source": "twitter",
    "author": "acoolcss03",
    "content": "Current SOTA imho:\n\n@FactoryAI with Gpt 5.1 for building\n\n@cursor_ai and Sonnet 4.5 with built in browser for UI tweaks https://t.co/EQ3SlGRdGH",
    "url": "https://x.com/acoolcss03/status/1990422509913579561",
    "timestamp": "2025-11-17T14:11:21.000Z",
    "metadata": {
      "conversation_id": "1990422509913579561",
      "likes": 2,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "github_discussion_374",
    "source": "github",
    "author": "vibl",
    "content": "[Discussion] 20M tokens promised, 1M tokens received...\n\nThe website https://factorycli.com/ promises free 20M tokens. After clicking on the link and signing up, I only received 1M tokens . ",
    "url": "https://github.com/Factory-AI/factory/discussions/374",
    "timestamp": "2025-11-17T00:05:46Z",
    "metadata": {
      "type": "discussion",
      "category": "General",
      "number": 374
    }
  },
  {
    "id": "reddit_1oz18qh",
    "source": "reddit",
    "author": "EggNo4904",
    "content": "not sure if i am the only one getting this, interestingly enough it had my card details saved tho.\n\nImages:\n\thttps://preview.redd.it/uu8xf048jp1g1.png?auto=webp&amp;s=9574291f2513a281eca97c75667653da65da086d\n",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1oz18qh/not_sure_if_i_am_the_only_one_getting_this/",
    "timestamp": "2025-11-16T23:56:02.000Z",
    "metadata": {
      "score": 3,
      "num_comments": 3,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "reddit_1oys5f5",
    "source": "reddit",
    "author": "SensitiveUpstairs803",
    "content": "Fix large file parsing crash issue.\n\nIf we have a large file Droid's file view tool will try to parse it and then crash because the file is to large but to solve the crashing you should add something that detects the size of the file then if its too large it will resort to using a powershell command instead of the built in droid file parser tool to parse a few lines of the file to get the format etc based on whatever the question involving the file is. Simple feature simple fix.",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1oys5f5/fix_large_file_parsing_crash_issue/",
    "timestamp": "2025-11-16T17:50:18.000Z",
    "metadata": {
      "score": 2,
      "num_comments": 1,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "reddit_1oydnzt",
    "source": "reddit",
    "author": "EggNo4904",
    "content": "When i put my real number this is what i get ( i moved it out, also the pretty print some vercel blocks heard a lot of droid would love to be able to try it)\n\nImages:\n\thttps://preview.redd.it/huzzfboe3k1g1.png?auto=webp&amp;s=f342b5e1a1ba7e0c301f58a658fd42ac56fe6535\n",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1oydnzt/when_i_put_my_real_number_this_is_what_i_get_i/",
    "timestamp": "2025-11-16T05:38:43.000Z",
    "metadata": {
      "score": 2,
      "num_comments": 4,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "github_issue_372",
    "source": "github",
    "author": "presidentoor",
    "content": "[Issue] Done Shield Disablement\n\nWhen unchecking the Drone Shield button and clicking save, the system responds with an error that it fails to disable the drone shield.",
    "url": "https://github.com/Factory-AI/factory/issues/372",
    "timestamp": "2025-11-15T21:48:31Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 372
    }
  },
  {
    "id": "github_issue_371",
    "source": "github",
    "author": "presidentoor",
    "content": "[Issue] Support Button Doesn't Work\n\nWhen logged in at app.factory.ai the drop down on the right with the support link, doesn't do anything.",
    "url": "https://github.com/Factory-AI/factory/issues/371",
    "timestamp": "2025-11-15T21:47:24Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 371
    }
  },
  {
    "id": "github_issue_370",
    "source": "github",
    "author": "aranej",
    "content": "[Issue] UserPromptSubmit hook stdout not injected into LLM context\n\n## Problem\n\nUserPromptSubmit hooks execute successfully but their stdout is not injected into the LLM context, despite [documentation](https://github.com/Factory-AI/factory/blob/main/docs/reference/hooks-reference.mdx#userpromptsubmit-decision-control) stating it should be.\n\n**Expected:** Hook stdout added to context before prompt processing  \n**Actual:** Hook runs, outputs to stdout, but LLM never receives it\n\n## Evidence\n\nDebug logging proves hook execution:\n\n```\n[2025-11-15 16:16:05.140072] U",
    "url": "https://github.com/Factory-AI/factory/issues/370",
    "timestamp": "2025-11-15T15:36:30Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 370
    }
  },
  {
    "id": "github_issue_369",
    "source": "github",
    "author": "BlackCatCmx",
    "content": "[Issue] The .factory/skills directory is created even when \"enableSkills\": false is set\n\nI have set \"enableSkills\": false in the settings.json, but every time droid starts it still automatically creates the .factory/skills directory.\n\nIs this expected behavior (e.g. I misunderstood how to configure it), or is this setting not intended to prevent the creation of the skills directory, or could this be a bug?",
    "url": "https://github.com/Factory-AI/factory/issues/369",
    "timestamp": "2025-11-15T14:38:14Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 369
    }
  },
  {
    "id": "github_issue_366",
    "source": "github",
    "author": "nikolas-sturm",
    "content": "[Issue] Extension not working in WSL\n\nHi, my usual setup consists of VSC connecting to WSL Debian where all my projects reside. The Claude Code extension for VSC works perfectly fine in this setup, however I found that the droid extension is not recognized by the CLI when a WSL workspace is open. It instantly starts working when i open the windows native droid CLI in a non WSL workspace in VSC. I also found that trying to install the extension through the `/settings` menu simply fails when inside WSL. ",
    "url": "https://github.com/Factory-AI/factory/issues/366",
    "timestamp": "2025-11-15T11:29:55Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 366
    }
  },
  {
    "id": "reddit_1oxk7bb",
    "source": "reddit",
    "author": "EggNo4904",
    "content": "Anybody else getting the pretty-print? vercel security etc. dk why it wont accept my card.\n\nThumbnail: self\n",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1oxk7bb/anybody_else_getting_the_prettyprint_vercel/",
    "timestamp": "2025-11-15T06:07:46.000Z",
    "metadata": {
      "score": 3,
      "num_comments": 3,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "reddit_1ox98ue",
    "source": "reddit",
    "author": "bentossell",
    "content": "Changelog: v0.26.0\n\n**New features**\n\n‚Ä¢ Session Favorites: New /favorite command to pin/unpin sessions, keeping your active projects at the top of the session list\n\n‚Ä¢ Enhanced Bug Reporting: The /bug command now zips session context, uploads it to Factory, and returns a shareable report ID automatically\n\n‚Ä¢ Cleaner Diff Viewer: Improved UI with horizontal lines instead of borders\n\n\n\n**Bug fixes &amp; smaller items**\n\n‚Ä¢ Always prompt to accept or reject generated specs and pass the correct labels to the UI flow\n\n‚Ä¢ dr",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1ox98ue/changelog_v0260/",
    "timestamp": "2025-11-14T21:33:18.000Z",
    "metadata": {
      "score": 7,
      "num_comments": 10,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "github_discussion_361",
    "source": "github",
    "author": "aaronschwartz",
    "content": "[Discussion] Does using the CLI in BYOK mode send data to Factory.ai?\n\nIf we configure the cli to use our own model through BYOK, does any of our data get sent to Factory.ai servers before being submitted to the model for processing? e.g. is there any codebase indexing or embedding being created by Factory.ai in the cloud before prompting the BYOK third party providers?",
    "url": "https://github.com/Factory-AI/factory/discussions/361",
    "timestamp": "2025-11-14T21:17:40Z",
    "metadata": {
      "type": "discussion",
      "category": "Questions",
      "number": 361
    }
  },
  {
    "id": "github_issue_360",
    "source": "github",
    "author": "hanlin-luo",
    "content": "[Issue] CJK double-width characters problem\n\nChinese input (CJK double-width characters) causes cursor misalignment once the input spans more than two lines.\nThis is due to the line editor not correctly implementing Unicode East Asian Width, resulting in incorrect wcwidth calculationsÔºåÔºàmaybeÔºâ.\nIt‚Äôs recommended to enable or fix proper wide-character support in the TUI/line editor being used.\n\nhttps://github.com/user-attachments/assets/7be46a43-0fe3-4e76-98c0-bea3727137e3",
    "url": "https://github.com/Factory-AI/factory/issues/360",
    "timestamp": "2025-11-14T20:31:10Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 360
    }
  },
  {
    "id": "reddit_1ox6p07",
    "source": "reddit",
    "author": "ShipSpecialist6727",
    "content": "Being charge for all limit overage while having credit balance\n\nhttps://preview.redd.it/apq9eqc22a1g1.png?width=713&amp;format=png&amp;auto=webp&amp;s=b55698314d83f7e933e7c750576ab10285a54f3a\n\nhttps://preview.redd.it/c4n0ms032a1g1.png?width=1088&amp;format=png&amp;auto=webp&amp;s=4c124b65440a28c118b9d8a714f0da7618eaf4aa\n\nhttps://preview.redd.it/h2scb4072a1g1.png?width=1226&amp;format=png&amp;auto=webp&amp;s=7fbc4d224122903a737d9f9b4ed0c2092e03ce72\n\n  \nI'm being charge for 40$ limit overage while having my credit balance from my referral .  \nThe support is to",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1ox6p07/being_charge_for_all_limit_overage_while_having/",
    "timestamp": "2025-11-14T19:54:09.000Z",
    "metadata": {
      "score": 3,
      "num_comments": 2,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "reddit_1owv5gf",
    "source": "reddit",
    "author": "bentossell",
    "content": "how to set up custom models with Groq in &lt;1 min\n\nhttps://reddit.com/link/1owv5gf/video/vfpxccohu71g1/player\n\nvideo above  \ndocs: [https://docs.factory.ai/cli/byok/groq](https://docs.factory.ai/cli/byok/groq)",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1owv5gf/how_to_set_up_custom_models_with_groq_in_1_min/",
    "timestamp": "2025-11-14T12:27:05.000Z",
    "metadata": {
      "score": 1,
      "num_comments": 0,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "reddit_1owpdgs",
    "source": "reddit",
    "author": "Informal-Spinach-345",
    "content": "Todo list with minimax m2\n\nAny one else have issues with Minimax M2 on vllm not being able to properly use the todo list? \n\n  \nThis is what the output looks like, it eventually moves on but I never see a todo list:\n\n   Let me create a comprehensive todo list that captures all the remaining work.\n\n   &lt;/think&gt;\n\n\n\n\n\n\n\n\n\n‚õ¨  &lt;think&gt;I need to fix the todo format - the todos parameter should be an array, not an object.\n\n   &lt;/think&gt;\n\n\n\n\n\n\n\n\n\n‚õ¨  &lt;think&gt;Let me check the todo structure more carefully. Looking",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1owpdgs/todo_list_with_minimax_m2/",
    "timestamp": "2025-11-14T06:41:19.000Z",
    "metadata": {
      "score": 1,
      "num_comments": 8,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "reddit_1owbvoj",
    "source": "reddit",
    "author": "bentossell",
    "content": "How should we post changelogs here?\n\nhey, i'm ben - dev rel at factory. you may have seen me answering comments.\n\nwe have a changelog now but has like 4/5 updates a week. its automated as a bot in our discord channel. \n\nshould we add anything here? if so, what format is best?",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1owbvoj/how_should_we_post_changelogs_here/",
    "timestamp": "2025-11-13T20:22:54.000Z",
    "metadata": {
      "score": 7,
      "num_comments": 4,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "reddit_1ow4spq",
    "source": "reddit",
    "author": "Rough-Aioli-7829",
    "content": "Why I can't register my email?\n\nImages:\n\thttps://preview.redd.it/rgbm3fcdr11g1.png?auto=webp&amp;s=b0a9871d3d6836057ca15067a94c8a71463ae5ca\n",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1ow4spq/why_i_cant_register_my_email/",
    "timestamp": "2025-11-13T15:58:33.000Z",
    "metadata": {
      "score": 2,
      "num_comments": 1,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "github_issue_348",
    "source": "github",
    "author": "aranej",
    "content": "[Issue] üöÄ Feature Request: Native Task Queue Support for Interactive Mode\n\n## üìã Summary\n\nRequest for **native task queuing functionality** in Droid CLI interactive mode, allowing users to queue multiple prompts for sequential or parallel processing without waiting for each task to complete before submitting the next one.\n\n## üéØ Problem Statement\n\n### Current User Experience (Frustrating)\n\n```bash\n> /sys-info is running...\n[User types: /init-prompt]\n‚ùå Command doesn't register - must wait for completion\n\n[After 30 seconds...]\n‚úÖ /sys-info completed\n\n[User must now re-typ",
    "url": "https://github.com/Factory-AI/factory/issues/348",
    "timestamp": "2025-11-13T09:01:07Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 348
    }
  },
  {
    "id": "github_issue_345",
    "source": "github",
    "author": "xianzou",
    "content": "[Issue] Running dorid in PowerShell produces no output\n\n<img width=\"1113\" height=\"626\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/0bddc80a-404e-4fee-9575-96c0cdc89b94\" />\n\nRunning dorid in PowerShell produces no outputÔºåI have already installed dorid.",
    "url": "https://github.com/Factory-AI/factory/issues/345",
    "timestamp": "2025-11-13T01:46:56Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 345
    }
  },
  {
    "id": "github_issue_341",
    "source": "github",
    "author": "580ai",
    "content": "[Issue] droidÔºöIt seems that the maximum output tokens will not be outputted anymore once they reach 8192\n\nIt will suddenly terminate and then remain stuck without returning any content until the maximum timeout is reached",
    "url": "https://github.com/Factory-AI/factory/issues/341",
    "timestamp": "2025-11-12T08:46:22Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 341
    }
  },
  {
    "id": "github_issue_340",
    "source": "github",
    "author": "korallis",
    "content": "[Issue] Multi Agent Issues in regards to aggrigated RPC\n\n 1. Describe the behavior\n     ‚Ä¢  When you invoke multiple tools via the parallel wrapper, you get no output until every sub-task completes.\n     ‚Ä¢  If any sub-task fails, the entire batch is reported as failed even though the other tasks actually ran.\n\n   2. Explain why it‚Äôs a problem\n     ‚Ä¢  You can‚Äôt see partial results or errors in real time.\n     ‚Ä¢  One failing branch masks useful output from the others, slowing triage and forcing retries.\n\n   3. Request the remedy\n     ‚Ä¢  Ask for streaming",
    "url": "https://github.com/Factory-AI/factory/issues/340",
    "timestamp": "2025-11-11T17:16:42Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 340
    }
  },
  {
    "id": "github_issue_337",
    "source": "github",
    "author": "etwk",
    "content": "[Issue] Make Copy Smooth\n\nDroid UI looks nice, but when I try to copy text to a editor to work further on it, there are some formatting issues:\n  - Frequent un-intended line breaks\n  - Empty space before each lines\n\nCan we make the transaction more smooth? It'll be huge UX enhancement.",
    "url": "https://github.com/Factory-AI/factory/issues/337",
    "timestamp": "2025-11-10T23:07:38Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 337
    }
  },
  {
    "id": "github_issue_335",
    "source": "github",
    "author": "etwk",
    "content": "[Issue] Subagent No Output\n\nTesting some subagents with the builtin models, the subagents seems running well but the main process never gets the output from the subagent task.\n\nUsing latest Droid (0.22.14) with the GPT-5-Codex model, getting this result:\n```\nAttempted to invoke the available subagents (code-reviewer, debugger) with simple greeting prompts, but each Task call returned ‚ÄúNo output received from task subagent,‚Äù so the requested ‚Äúhi‚Äù response could not be produced.\n```",
    "url": "https://github.com/Factory-AI/factory/issues/335",
    "timestamp": "2025-11-10T12:55:34Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 335
    }
  },
  {
    "id": "github_issue_334",
    "source": "github",
    "author": "etwk",
    "content": "[Issue] droid exec will change default model for the main process\n\nCurrently droid exec will change default model for the main process, maybe we should change this partly because of convenience, and partly because of process separation, not letting 2 unrelated process interfering in any possible way.",
    "url": "https://github.com/Factory-AI/factory/issues/334",
    "timestamp": "2025-11-10T12:42:52Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 334
    }
  },
  {
    "id": "github_issue_331",
    "source": "github",
    "author": "spionkind",
    "content": "[Issue] Issue with GPT5 Codex and Custom Model on Droid\n\n Hi,\n\nwhenever I chosed GPT5-codex model it show this error message:\nError: 400 Invalid 'tools[40].name': string too long. Expected a string with maximum length 64, but got a string with length 66 instead.\n\nand when I try with custom model (qwen3 coder), it shows this:\nError: 400 <400> InternalError.Algo.InvalidParameter: The length of the tool name cannot exceed 64.\n\nDroid still works well with other model suchas sonnet 4.5, glm 4.6\n\nPlease help me on this issues\n\nBest regards,\nGiang",
    "url": "https://github.com/Factory-AI/factory/issues/331",
    "timestamp": "2025-11-09T16:19:30Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 331
    }
  },
  {
    "id": "github_issue_330",
    "source": "github",
    "author": "olsavmic",
    "content": "[Issue] Feature Request: Implement Statusline Support\n\n  Add support for customizable statuslines in Factory's CLI interface, as documented in [Claude Code's statusline\n  feature](https://code.claude.com/docs/en/statusline).\n\n  Motivation\n\n  Statuslines provide persistent contextual information at the bottom of the interface, which is incredibly helpful for:\n   ‚Ä¢  Git awareness: Immediately see the current branch without running git status\n   ‚Ä¢  Directory context: Know your current working directory at a glance\n   ‚Ä¢  Session info: Display the curren",
    "url": "https://github.com/Factory-AI/factory/issues/330",
    "timestamp": "2025-11-09T11:34:21Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 330
    }
  },
  {
    "id": "github_issue_329",
    "source": "github",
    "author": "TheSingular",
    "content": "[Issue] Spec mode hides reasoning level effort in model name\n\nWhen using the spec mode, you cannot see the reasoning effort of the model you have selected (if it supports reasoning).\nYou can still change the reasoning effort via the tab key, but you cannot see its effect at all. Other modes properly display the reasoning effort in parentheses.\n\nHow to reproduce:\n1. Use model Sonnet 4.5 with low reasoning effort, do not choose a separate model for the spec model.\n2. Toggle to spec mode via ctrl + t.\n3. Observe the parentheses containing the reasoning effort",
    "url": "https://github.com/Factory-AI/factory/issues/329",
    "timestamp": "2025-11-09T09:12:43Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 329
    }
  },
  {
    "id": "github_issue_328",
    "source": "github",
    "author": "a112121788",
    "content": "[Issue] custom model support reasoning\n\n",
    "url": "https://github.com/Factory-AI/factory/issues/328",
    "timestamp": "2025-11-08T15:47:20Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 328
    }
  },
  {
    "id": "github_issue_325",
    "source": "github",
    "author": "Evan-Kim2028",
    "content": "[Issue] Task subagent runs tools but returns no final message (intermittent)\n\nSummary\n- Intermittently, Task executions succeed and run tools (Grep/Read/Glob/TodoWrite) but no final assistant message is emitted, and the wrapper surfaces: \"No output received from task subagent.\" This blocks using dbt droids for reviews.\n\nEnvironment\n- OS: macOS darwin 24.6.0\n- Factory CLI/session: latest as of 2025-11-07\n- Model: OpenAI GPT-5\n- gh: 2.80.0\n\nReproduction (today)\n1) Launch Task with subagent_type=\"dbt-quality-droid\" on local repo /Users/evandekim/Documents/spellbook (branch: ",
    "url": "https://github.com/Factory-AI/factory/issues/325",
    "timestamp": "2025-11-07T21:38:02Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 325
    }
  },
  {
    "id": "github_issue_321",
    "source": "github",
    "author": "nilzzzzzz",
    "content": "[Issue] Droid exec --output-format debug is not returning the result\n\nWe rely heavily on `droid exec` but since one of the last updates there is a huge issue. Running `droid exec --output-format debug` does not return anymore the result but just the debug outputs before:\n\nReproduction:\n\n```\ndroid exec \"which services does the backend have\" --output-format debug\n\n{\"type\":\"system\",\"subtype\":\"init\",\"cwd\":\"/Users/nilz/Repositories/awork-backend\",\"session_id\":\"273c1ae2-ffec-4ef5-b748-e04d713000fa\",\"tools\":[\"Read\",\"LS\",\"Execute\",\"Edit\",\"ApplyPatch\",\"Grep\",\"Glob\",\"Create",
    "url": "https://github.com/Factory-AI/factory/issues/321",
    "timestamp": "2025-11-07T12:11:44Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 321
    }
  },
  {
    "id": "github_issue_319",
    "source": "github",
    "author": "Bladed3d",
    "content": "[Issue] \"Endless Processing\" When using custom model openrouter: Grok-Code-Fast-1\n\nWhen using custom model openrouter: Grok-Code-Fast-1 after giving it a task, Droid will keep working on that until I press ESC then display context it has been building up. Upon further review, it seems that Droid using Grok is having a conversation with itself, forgetting to include me and wait for my actual participation:\n\n(This is just some of the context...)\n\nConfirming Dashboard Functionality\n   ‚Ä¢  The dashboard no longer shows duplicates, displaying only the current session's 1\n      root ",
    "url": "https://github.com/Factory-AI/factory/issues/319",
    "timestamp": "2025-11-06T20:19:04Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 319
    }
  },
  {
    "id": "github_discussion_309",
    "source": "github",
    "author": "msneijders",
    "content": "[Discussion] Droid CLI: configurable timeouts per mcp server\n\n**Motivation**: I use a 'Language Server Protocol' mcp for adding tools to query symbols and find_usage and such. But on large projects and during first-time use they can take quite some time before giving responses; causing timeouts in droid cli. If I could configure a larger timeout for this specific mcp server it could work better.",
    "url": "https://github.com/Factory-AI/factory/discussions/309",
    "timestamp": "2025-11-04T10:48:14Z",
    "metadata": {
      "type": "discussion",
      "category": "Feature requests",
      "number": 309
    }
  },
  {
    "id": "github_discussion_240",
    "source": "github",
    "author": "factory-ben",
    "content": "[Discussion] Mini Changelog\n\n<img width=\"686\" height=\"397\" alt=\"Screenshot 2025-10-22 at 14 58 16\" src=\"https://github.com/user-attachments/assets/0288d87c-55b1-44b4-91cb-33d745fc052b\" />\r\n",
    "url": "https://github.com/Factory-AI/factory/discussions/240",
    "timestamp": "2025-10-23T09:45:14Z",
    "metadata": {
      "type": "discussion",
      "category": "Factory Official",
      "number": 240
    }
  },
  {
    "id": "github_discussion_225",
    "source": "github",
    "author": "JohnDotOwl",
    "content": "[Discussion] Change Log\n\nCan we have more updated change logs somewhere if possible. \r\n\r\nSuccessfully updated to version 0.21.5 Just saw this ",
    "url": "https://github.com/Factory-AI/factory/discussions/225",
    "timestamp": "2025-10-21T09:52:33Z",
    "metadata": {
      "type": "discussion",
      "category": "Feature requests",
      "number": 225
    }
  },
  {
    "id": "github_discussion_223",
    "source": "github",
    "author": "JohnDotOwl",
    "content": "[Discussion] [Discussion] Droid Exec Headless Streaming with output format (JSON)\n\nDroid Exec (Headless)\r\nIt make sense to use --output-format json if you're running a headless droid exec as that's the best way to programmatically manage the headless droid. The issue for me is i can't see the process and potentially stop it without --output-format debug and i can't run both output format. \r\n\r\nShould we consider having a different parameter for \"streaming\" , it's not so much for debugging but more to manage the task itself. ",
    "url": "https://github.com/Factory-AI/factory/discussions/223",
    "timestamp": "2025-10-21T02:46:01Z",
    "metadata": {
      "type": "discussion",
      "category": "Feature requests",
      "number": 223
    }
  },
  {
    "id": "github_discussion_214",
    "source": "github",
    "author": "0xStuart",
    "content": "[Discussion] JetBrains Plugin\n\nThe documentation says there is a JetBrains Plugin in the marketplace, but I can't find it.",
    "url": "https://github.com/Factory-AI/factory/discussions/214",
    "timestamp": "2025-10-19T19:55:35Z",
    "metadata": {
      "type": "discussion",
      "category": "Questions",
      "number": 214
    }
  },
  {
    "id": "github_discussion_164",
    "source": "github",
    "author": "tgerighty",
    "content": "[Discussion] Droid Exec - custom models supported?\n\ncan we have support for custom models in droid exec? even if it were just simple endpoint/key.",
    "url": "https://github.com/Factory-AI/factory/discussions/164",
    "timestamp": "2025-10-10T18:34:32Z",
    "metadata": {
      "type": "discussion",
      "category": "Feature requests",
      "number": 164
    }
  },
  {
    "id": "github_discussion_151",
    "source": "github",
    "author": "snowarch",
    "content": "[Discussion] Sound or notification when completed task\n\nIt would be useful to have some kind of sound or notification in the system when the agent has completed the task. Droid CLI, Arch Linux.",
    "url": "https://github.com/Factory-AI/factory/discussions/151",
    "timestamp": "2025-10-09T10:20:14Z",
    "metadata": {
      "type": "discussion",
      "category": "Feature requests",
      "number": 151
    }
  },
  {
    "id": "github_discussion_108",
    "source": "github",
    "author": "factory-ben",
    "content": "[Discussion] Release v1.3.220\n\n---\r\n\r\nThis release brings HTTP MCP server support, a `/compress` command to optimize your context usage and droid exec for CDE.\r\n\r\n---\r\n\r\n## HTTP MCP Server Support\r\n\r\nFactory now supports streamable HTTP-based Model Context Protocol (MCP) servers in addition to stdio-based servers. This enables you to connect to MCP servers running as web services, making it easier to integrate with cloud-hosted tools and services.\r\n\r\nWhen adding an MCP server, Factory automatically detects whether it's HTTP o",
    "url": "https://github.com/Factory-AI/factory/discussions/108",
    "timestamp": "2025-10-03T20:21:56Z",
    "metadata": {
      "type": "discussion",
      "category": "Factory Official",
      "number": 108
    }
  },
  {
    "id": "github_discussion_99",
    "source": "github",
    "author": "Evan-Kim2028",
    "content": "[Discussion] Droid source code\n\nIs droid closed source? I am not able to find any code. I would like to be able to see how the droid tools are implemented if the code is available to see",
    "url": "https://github.com/Factory-AI/factory/discussions/99",
    "timestamp": "2025-10-02T17:51:27Z",
    "metadata": {
      "type": "discussion",
      "category": "Questions",
      "number": 99
    }
  },
  {
    "id": "github_discussion_95",
    "source": "github",
    "author": "factory-ben",
    "content": "[Discussion] CLI v0.16.0 Release Notes\n\n- Sonnet 4.5 model is now available\r\n- Clear chat input using double ESC or Ctrl-C\r\n- User-configured allow and deny list of commands to execute\r\n- Option to disable droid commit co-authoring\r\n- Auth using FACTORY_API_KEY\r\n- Fixed UI bugs due to resizing",
    "url": "https://github.com/Factory-AI/factory/discussions/95",
    "timestamp": "2025-10-01T20:05:01Z",
    "metadata": {
      "type": "discussion",
      "category": "Factory Official",
      "number": 95
    }
  },
  {
    "id": "github_discussion_92",
    "source": "github",
    "author": "msneijders",
    "content": "[Discussion] MCP tools filtering\n\nI would like to configure exactly what tools of a MCP server should be made available.\r\n\r\nMotivation: MCP servers with overlapping functionality and too many unneeded tools is confusing the models.",
    "url": "https://github.com/Factory-AI/factory/discussions/92",
    "timestamp": "2025-10-01T09:07:33Z",
    "metadata": {
      "type": "discussion",
      "category": "Feature requests",
      "number": 92
    }
  },
  {
    "id": "github_discussion_82",
    "source": "github",
    "author": "mweichert",
    "content": "[Discussion] Web API?\n\nHi there! Is there a web API to create and manage sessions?",
    "url": "https://github.com/Factory-AI/factory/discussions/82",
    "timestamp": "2025-09-29T13:16:25Z",
    "metadata": {
      "type": "discussion",
      "category": "Questions",
      "number": 82
    }
  },
  {
    "id": "github_discussion_72",
    "source": "github",
    "author": "rubendn",
    "content": "[Discussion] Droid selection in CLI?\n\nIs there a way to use one of the specialized Droids (Product, Tutorial, etc) via the CLI?  I don't see a way to select in the slash commands.\r\n\r\nAlso, is there a way on Windows to select a local workspace path besides ~\\?\r\n\r\nThanks!",
    "url": "https://github.com/Factory-AI/factory/discussions/72",
    "timestamp": "2025-09-29T05:17:49Z",
    "metadata": {
      "type": "discussion",
      "category": "Questions",
      "number": 72
    }
  },
  {
    "id": "github_discussion_66",
    "source": "github",
    "author": "factory-ben",
    "content": "[Discussion] 2 new community builds: use claude/codex max subscriptions with droid\n\n- [Factory CLI with ChatGPT Codex / Claude subscription via CLIProxyAPI](https://gist.github.com/chandika/c4b64c5b8f5e29f6112021d46c159fdd) - Guide to run Factory CLI against Claude Code Max or ChatGPT Codex through CLIProxyAPI by [chandika](https://github.com/chandika)\r\n- [Factory CLI with Claude subscription via CLIProxyAPI](https://gist.github.com/ben-vargas/9f1a14ac5f78d10eba56be437b7c76e5) - Setup instructions for using Factory CLI with Claude Code Max through CLIProxyAPI by [ben-vargas](ht",
    "url": "https://github.com/Factory-AI/factory/discussions/66",
    "timestamp": "2025-09-27T19:15:40Z",
    "metadata": {
      "type": "discussion",
      "category": "Show + tell",
      "number": 66
    }
  },
  {
    "id": "github_discussion_65",
    "source": "github",
    "author": "jimkyndemeyer",
    "content": "[Discussion] BYOK with Anthropic models on Amazon Bedrock\n\nWould be great to have the option of using Amazon Bedrock for Anthropic models with BYOK.\r\n\r\nAnthropic has official SDKs for Bedrock, but the model env config is a bit different:\r\n- AWS region\r\n- Access key id\r\n- Secret access key",
    "url": "https://github.com/Factory-AI/factory/discussions/65",
    "timestamp": "2025-09-27T09:46:55Z",
    "metadata": {
      "type": "discussion",
      "category": "Feature requests",
      "number": 65
    }
  },
  {
    "id": "github_discussion_59",
    "source": "github",
    "author": "factory-ben",
    "content": "[Discussion] #1 on Terminal Bench\n\n<img width=\"1582\" height=\"972\" alt=\"Screenshot 2025-09-25 at 17 15 56\" src=\"https://github.com/user-attachments/assets/9e9c80b6-825c-41cc-b8c7-236b21e3f61c\" />\r\n\r\nRead how we did it: https://factory.ai/news/terminal-bench",
    "url": "https://github.com/Factory-AI/factory/discussions/59",
    "timestamp": "2025-09-25T19:22:25Z",
    "metadata": {
      "type": "discussion",
      "category": "Factory Official",
      "number": 59
    }
  },
  {
    "id": "github_discussion_32",
    "source": "github",
    "author": "factory-ben",
    "content": "[Discussion] CLI v0.7.0 Release Notes\n\nCLI Release (0.7.0)\r\n\r\n- Autonomy level selection: Users can now select any preferred autonomy level when confirming the ExitSpec tool\r\n- Claude reasoning support: Added support for Claude's reasoning capabilities\r\n- Session resumption: Users can now resume existing sessions when operating in Exec Mode\r\n- Image reading capabilities: The CLI can now read and process images",
    "url": "https://github.com/Factory-AI/factory/discussions/32",
    "timestamp": "2025-09-19T20:15:48Z",
    "metadata": {
      "type": "discussion",
      "category": "Factory Official",
      "number": 32
    }
  },
  {
    "id": "github_discussion_25",
    "source": "github",
    "author": "DannyAziz",
    "content": "[Discussion] Change model even if I've already written a prompt out\n\nSometimes I write a message, then realise I want to drop down to Sonnet, and I have to delete my message to hit the slash command. I wish there was a way to do this without deleting everything.",
    "url": "https://github.com/Factory-AI/factory/discussions/25",
    "timestamp": "2025-09-16T22:58:36Z",
    "metadata": {
      "type": "discussion",
      "category": "Feature requests",
      "number": 25
    }
  }
]