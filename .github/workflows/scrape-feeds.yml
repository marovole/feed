name: Scrape Feeds

on:
  schedule:
    - cron: '*/10 * * * *'  # Every 10 minutes
  workflow_dispatch:  # Allow manual trigger
  push:
    branches: [main]  # Also run on push for testing

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ github.token }}

      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run scraper
        env:
          GITHUB_TOKEN: ${{ github.token }}
          GITHUB_REPO: ${{ secrets.GH_REPO }}
          APIFY_TOKEN: ${{ secrets.APIFY_TOKEN }}
          TEAM_TWITTER_USERNAMES: ${{ secrets.TEAM_TWITTER_USERNAMES }}
        run: node src/scraper-cli.js

      - name: Commit and push feed data
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add docs/data/feed.json docs/data/seen.json
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "Update feed data [skip ci]"
            # Try to push, if it fails pull and retry
            git push origin HEAD:main || (git pull --rebase=false --no-edit origin main && git push origin HEAD:main)
          fi
