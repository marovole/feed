[
  {
    "id": "twitter_1989461969720823879",
    "source": "twitter",
    "author": "curiouslychase",
    "content": "If you're an engineering leader and you're not enabling your engineering teams to use @ampcode or @factoryai Droid or @cursor, you're leaving massive productivity gains on the table.",
    "url": "https://x.com/curiouslychase/status/1989461969720823879",
    "timestamp": "2025-11-14T22:34:30.000Z",
    "metadata": {
      "conversation_id": "1989461969720823879",
      "likes": 1,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1989461566379737449",
    "source": "twitter",
    "author": "davidrsdlife",
    "content": "@jackfriks @UltraLinx droid from @FactoryAI though‚Ä¶\n\nreally, really good.",
    "url": "https://x.com/davidrsdlife/status/1989461566379737449",
    "timestamp": "2025-11-14T22:32:54.000Z",
    "metadata": {
      "conversation_id": "1989461566379737449",
      "likes": 0,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1989461400482357617",
    "source": "twitter",
    "author": "bradvangelder",
    "content": "@ben_vargas @FactoryAI this is big man!",
    "url": "https://x.com/bradvangelder/status/1989461400482357617",
    "timestamp": "2025-11-14T22:32:14.000Z",
    "metadata": {
      "conversation_id": "1989461400482357617",
      "likes": 1,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1989460040328384888",
    "source": "twitter",
    "author": "captaink99",
    "content": "@FactoryAI a",
    "url": "https://x.com/captaink99/status/1989460040328384888",
    "timestamp": "2025-11-14T22:26:50.000Z",
    "metadata": {
      "conversation_id": "1989460040328384888",
      "likes": 0,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1989456110781391007",
    "source": "twitter",
    "author": "jc50000000",
    "content": "@zivdotcat All of them and use @FactoryAI",
    "url": "https://x.com/jc50000000/status/1989456110781391007",
    "timestamp": "2025-11-14T22:11:13.000Z",
    "metadata": {
      "conversation_id": "1989456110781391007",
      "likes": 1,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1989449304621408672",
    "source": "twitter",
    "author": "Danishafzalkhan",
    "content": "@francesca_lab @RhysSullivan @FactoryAI I did and the freezes mid code made me cancel my sub. I had to ctrl c and continue every other time.",
    "url": "https://x.com/Danishafzalkhan/status/1989449304621408672",
    "timestamp": "2025-11-14T21:44:11.000Z",
    "metadata": {
      "conversation_id": "1989449304621408672",
      "likes": 0,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "reddit_1ox98ue",
    "source": "reddit",
    "author": "bentossell",
    "content": "Changelog: v0.26.0\n\n**New features**\n\n‚Ä¢ Session Favorites: New /favorite command to pin/unpin sessions, keeping your active projects at the top of the session list\n\n‚Ä¢ Enhanced Bug Reporting: The /bug command now zips session context, uploads it to Factory, and returns a shareable report ID automatically\n\n‚Ä¢ Cleaner Diff Viewer: Improved UI with horizontal lines instead of borders\n\n\n\n**Bug fixes &amp; smaller items**\n\n‚Ä¢ Always prompt to accept or reject generated specs and pass the correct labels to the UI flow\n\n‚Ä¢ dr",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1ox98ue/changelog_v0260/",
    "timestamp": "2025-11-14T21:33:18.000Z",
    "metadata": {
      "score": 2,
      "num_comments": 2,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "twitter_1989446153130446986",
    "source": "twitter",
    "author": "sarlalian",
    "content": "@tridentasia @melodykoh @AnthropicAI @FactoryAI Humans always underestimate as well.",
    "url": "https://x.com/sarlalian/status/1989446153130446986",
    "timestamp": "2025-11-14T21:31:39.000Z",
    "metadata": {
      "conversation_id": "1989446153130446986",
      "likes": 0,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "github_discussion_361",
    "source": "github",
    "author": "aaronschwartz",
    "content": "[Discussion] Does using the CLI in BYOK mode send data to Factory.ai?\n\nIf we configure the cli to use our own model through BYOK, does any of our data get sent to Factory.ai servers before being submitted to the model for processing? e.g. is there any codebase indexing or embedding being created by Factory.ai in the cloud before prompting the BYOK third party providers?",
    "url": "https://github.com/Factory-AI/factory/discussions/361",
    "timestamp": "2025-11-14T21:17:40Z",
    "metadata": {
      "type": "discussion",
      "category": "Questions",
      "number": 361
    }
  },
  {
    "id": "twitter_1989441487327965490",
    "source": "twitter",
    "author": "bradvangelder",
    "content": "@CloudTrader4 @OpenAI @FactoryAI I've been loving gpt-5.1-codex-mini for the last couple of hours...\n\nHow has glm 4.6 been performing for you lately?",
    "url": "https://x.com/bradvangelder/status/1989441487327965490",
    "timestamp": "2025-11-14T21:13:07.000Z",
    "metadata": {
      "conversation_id": "1989441487327965490",
      "likes": 0,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "github_issue_360",
    "source": "github",
    "author": "hanlin-luo",
    "content": "[Issue] CJK double-width characters problem\n\nChinese input (CJK double-width characters) causes cursor misalignment once the input spans more than two lines.\nThis is due to the line editor not correctly implementing Unicode East Asian Width, resulting in incorrect wcwidth calculationsÔºåÔºàmaybeÔºâ.\nIt‚Äôs recommended to enable or fix proper wide-character support in the TUI/line editor being used.\n\nhttps://github.com/user-attachments/assets/7be46a43-0fe3-4e76-98c0-bea3727137e3",
    "url": "https://github.com/Factory-AI/factory/issues/360",
    "timestamp": "2025-11-14T20:31:10Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 360
    }
  },
  {
    "id": "twitter_1989423126388817977",
    "source": "twitter",
    "author": "ben_vargas",
    "content": "@iamRamavar @trungns95vn @FactoryAI I'd suggest doing the login/oauth workflow before setting the amp.url in ~/.config/amp/settings.json - there's probably additionally handling needed for the URL redirects for oauth workflow that isn't done in CLIProxyAPI fork.",
    "url": "https://x.com/ben_vargas/status/1989423126388817977",
    "timestamp": "2025-11-14T20:00:09.000Z",
    "metadata": {
      "conversation_id": "1989423126388817977",
      "likes": 0,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "reddit_1ox6p07",
    "source": "reddit",
    "author": "ShipSpecialist6727",
    "content": "Being charge for all limit overage while having credit balance\n\nhttps://preview.redd.it/apq9eqc22a1g1.png?width=713&amp;format=png&amp;auto=webp&amp;s=b55698314d83f7e933e7c750576ab10285a54f3a\n\nhttps://preview.redd.it/c4n0ms032a1g1.png?width=1088&amp;format=png&amp;auto=webp&amp;s=4c124b65440a28c118b9d8a714f0da7618eaf4aa\n\nhttps://preview.redd.it/h2scb4072a1g1.png?width=1226&amp;format=png&amp;auto=webp&amp;s=7fbc4d224122903a737d9f9b4ed0c2092e03ce72\n\n  \nI'm being charge for 40$ limit overage while having my credit balance from my referral .  \nThe support is to",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1ox6p07/being_charge_for_all_limit_overage_while_having/",
    "timestamp": "2025-11-14T19:54:09.000Z",
    "metadata": {
      "score": 2,
      "num_comments": 2,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "twitter_1989421388223091038",
    "source": "twitter",
    "author": "iamRamavar",
    "content": "@trungns95vn @ben_vargas @FactoryAI Hi @ben_vargas - amp login after setting proxy is thorwing \"404 page not found\"",
    "url": "https://x.com/iamRamavar/status/1989421388223091038",
    "timestamp": "2025-11-14T19:53:15.000Z",
    "metadata": {
      "conversation_id": "1989421388223091038",
      "likes": 0,
      "retweets": 0,
      "replies": 1,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1989420741197222321",
    "source": "twitter",
    "author": "MinChonChiSF",
    "content": "@melodykoh @AnthropicAI @FactoryAI The active QA time is an interesting tradeoff for using AI coding agents.",
    "url": "https://x.com/MinChonChiSF/status/1989420741197222321",
    "timestamp": "2025-11-14T19:50:41.000Z",
    "metadata": {
      "conversation_id": "1989420741197222321",
      "likes": 0,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1989413935561543957",
    "source": "twitter",
    "author": "aeitroc",
    "content": "@thdxr @FactoryAI",
    "url": "https://x.com/aeitroc/status/1989413935561543957",
    "timestamp": "2025-11-14T19:23:38.000Z",
    "metadata": {
      "conversation_id": "1989413935561543957",
      "likes": 1,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1989412481564135810",
    "source": "twitter",
    "author": "milesprojolivia",
    "content": "exactly but most miss that context management only matters if anyone can build with it\n\n@FactoryAI droids are powerful but the real shift is when non-devs can deploy agents with their own knowledge. accessibility > raw capability\n\nin 2 years every business has custom agents. whoever makes it dead simple wins\n\n#AI #AIAgents #NoCode",
    "url": "https://x.com/milesprojolivia/status/1989412481564135810",
    "timestamp": "2025-11-14T19:17:51.000Z",
    "metadata": {
      "conversation_id": "1989412481564135810",
      "likes": 1,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1989411336737231350",
    "source": "twitter",
    "author": "bentossell",
    "content": "@prannoy_p @dakshgup @FactoryAI as we intend it to üòä",
    "url": "https://x.com/bentossell/status/1989411336737231350",
    "timestamp": "2025-11-14T19:13:18.000Z",
    "metadata": {
      "conversation_id": "1989411336737231350",
      "likes": 0,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1989411109582114938",
    "source": "twitter",
    "author": "bentossell",
    "content": "@laplacian_demon @FactoryAI üîî",
    "url": "https://x.com/bentossell/status/1989411109582114938",
    "timestamp": "2025-11-14T19:12:24.000Z",
    "metadata": {
      "conversation_id": "1989411109582114938",
      "likes": 0,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1989410925430837614",
    "source": "twitter",
    "author": "bentossell",
    "content": "@melodykoh @AnthropicAI @FactoryAI üî•",
    "url": "https://x.com/bentossell/status/1989410925430837614",
    "timestamp": "2025-11-14T19:11:40.000Z",
    "metadata": {
      "conversation_id": "1989410925430837614",
      "likes": 2,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1989409263526228440",
    "source": "twitter",
    "author": "tridentasia",
    "content": "@melodykoh @AnthropicAI @FactoryAI Agents always overestimate time taken in implementing a plan.",
    "url": "https://x.com/tridentasia/status/1989409263526228440",
    "timestamp": "2025-11-14T19:05:04.000Z",
    "metadata": {
      "conversation_id": "1989409263526228440",
      "likes": 0,
      "retweets": 0,
      "replies": 1,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1989405646245302719",
    "source": "twitter",
    "author": "martin_ict_algo",
    "content": "@aeitroc @Star_Knight12 @FactoryAI How have you found the plans, like the $200 plan, you burn through the 200mill tokens?",
    "url": "https://x.com/martin_ict_algo/status/1989405646245302719",
    "timestamp": "2025-11-14T18:50:42.000Z",
    "metadata": {
      "conversation_id": "1989405646245302719",
      "likes": 0,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1989403060578521468",
    "source": "twitter",
    "author": "aeitroc",
    "content": "@Star_Knight12 Use Droid from @FactoryAI , plan with GPT 5.1,execute with Claude. It's the best you could do with the models we have so far.",
    "url": "https://x.com/aeitroc/status/1989403060578521468",
    "timestamp": "2025-11-14T18:40:25.000Z",
    "metadata": {
      "conversation_id": "1989403060578521468",
      "likes": 6,
      "retweets": 1,
      "replies": 1,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1989395903082631510",
    "source": "twitter",
    "author": "Mng64218162",
    "content": "@melodykoh @AnthropicAI @FactoryAI most of the time you save now by using ai will be the bottleneck later when your project gets bigger and then you will need an engineer to maintain it and an engineer will need much more time than what you saved to understand what ai did and fix many stuff if that was possible",
    "url": "https://x.com/Mng64218162/status/1989395903082631510",
    "timestamp": "2025-11-14T18:11:59.000Z",
    "metadata": {
      "conversation_id": "1989395903082631510",
      "likes": 1,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "reddit_1owv5gf",
    "source": "reddit",
    "author": "bentossell",
    "content": "how to set up custom models with Groq in &lt;1 min\n\nhttps://reddit.com/link/1owv5gf/video/vfpxccohu71g1/player\n\nvideo above  \ndocs: [https://docs.factory.ai/cli/byok/groq](https://docs.factory.ai/cli/byok/groq)",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1owv5gf/how_to_set_up_custom_models_with_groq_in_1_min/",
    "timestamp": "2025-11-14T12:27:05.000Z",
    "metadata": {
      "score": 1,
      "num_comments": 0,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "reddit_1owpdgs",
    "source": "reddit",
    "author": "Informal-Spinach-345",
    "content": "Todo list with minimax m2\n\nAny one else have issues with Minimax M2 on vllm not being able to properly use the todo list? \n\n  \nThis is what the output looks like, it eventually moves on but I never see a todo list:\n\n   Let me create a comprehensive todo list that captures all the remaining work.\n\n   &lt;/think&gt;\n\n\n\n\n\n\n\n\n\n‚õ¨  &lt;think&gt;I need to fix the todo format - the todos parameter should be an array, not an object.\n\n   &lt;/think&gt;\n\n\n\n\n\n\n\n\n\n‚õ¨  &lt;think&gt;Let me check the todo structure more carefully. Looking",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1owpdgs/todo_list_with_minimax_m2/",
    "timestamp": "2025-11-14T06:41:19.000Z",
    "metadata": {
      "score": 1,
      "num_comments": 6,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "reddit_1owbvoj",
    "source": "reddit",
    "author": "bentossell",
    "content": "How should we post changelogs here?\n\nhey, i'm ben - dev rel at factory. you may have seen me answering comments.\n\nwe have a changelog now but has like 4/5 updates a week. its automated as a bot in our discord channel. \n\nshould we add anything here? if so, what format is best?",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1owbvoj/how_should_we_post_changelogs_here/",
    "timestamp": "2025-11-13T20:22:54.000Z",
    "metadata": {
      "score": 7,
      "num_comments": 4,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "reddit_1ow4spq",
    "source": "reddit",
    "author": "Rough-Aioli-7829",
    "content": "Why I can't register my email?\n\nImages:\n\thttps://preview.redd.it/rgbm3fcdr11g1.png?auto=webp&amp;s=b0a9871d3d6836057ca15067a94c8a71463ae5ca\n",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1ow4spq/why_i_cant_register_my_email/",
    "timestamp": "2025-11-13T15:58:33.000Z",
    "metadata": {
      "score": 2,
      "num_comments": 1,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "reddit_1ow0203",
    "source": "reddit",
    "author": "vargalas",
    "content": "It's the worst onboarding experience ever\n\nThe provided cli instruction doesn't work, curl is complaining about self-signed certificate. The support link (after logging in) doesn't work. I tried to contact the sales on the homepage, but you cannot write them, they will contact. if they want. \n\nSo no Droid for me. I cannot see how they get customers. ",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1ow0203/its_the_worst_onboarding_experience_ever/",
    "timestamp": "2025-11-13T12:42:42.000Z",
    "metadata": {
      "score": 0,
      "num_comments": 3,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "github_issue_348",
    "source": "github",
    "author": "aranej",
    "content": "[Issue] üöÄ Feature Request: Native Task Queue Support for Interactive Mode\n\n## üìã Summary\n\nRequest for **native task queuing functionality** in Droid CLI interactive mode, allowing users to queue multiple prompts for sequential or parallel processing without waiting for each task to complete before submitting the next one.\n\n## üéØ Problem Statement\n\n### Current User Experience (Frustrating)\n\n```bash\n> /sys-info is running...\n[User types: /init-prompt]\n‚ùå Command doesn't register - must wait for completion\n\n[After 30 seconds...]\n‚úÖ /sys-info completed\n\n[User must now re-typ",
    "url": "https://github.com/Factory-AI/factory/issues/348",
    "timestamp": "2025-11-13T09:01:07Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 348
    }
  },
  {
    "id": "github_issue_345",
    "source": "github",
    "author": "xianzou",
    "content": "[Issue] Running dorid in PowerShell produces no output\n\n<img width=\"1113\" height=\"626\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/0bddc80a-404e-4fee-9575-96c0cdc89b94\" />\n\nRunning dorid in PowerShell produces no outputÔºåI have already installed dorid.",
    "url": "https://github.com/Factory-AI/factory/issues/345",
    "timestamp": "2025-11-13T01:46:56Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 345
    }
  },
  {
    "id": "reddit_1ovbn7q",
    "source": "reddit",
    "author": "UrAn8",
    "content": "Anyone having issues with the Bridge?\n\nLast few days bridge has been disconnecting frequently. then it started crashing after opening. Restarting cpu didn't help so I deleted the bridge, downloaded it again, restarted my computer, and now it's no longer crashing, but won't reconnect to any old or new sessions. Anyone else having this issue? ",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1ovbn7q/anyone_having_issues_with_the_bridge/",
    "timestamp": "2025-11-12T17:34:16.000Z",
    "metadata": {
      "score": 1,
      "num_comments": 3,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "github_issue_341",
    "source": "github",
    "author": "580ai",
    "content": "[Issue] droidÔºöIt seems that the maximum output tokens will not be outputted anymore once they reach 8192\n\nIt will suddenly terminate and then remain stuck without returning any content until the maximum timeout is reached",
    "url": "https://github.com/Factory-AI/factory/issues/341",
    "timestamp": "2025-11-12T08:46:22Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 341
    }
  },
  {
    "id": "github_issue_340",
    "source": "github",
    "author": "korallis",
    "content": "[Issue] Multi Agent Issues in regards to aggrigated RPC\n\n 1. Describe the behavior\n     ‚Ä¢  When you invoke multiple tools via the parallel wrapper, you get no output until every sub-task completes.\n     ‚Ä¢  If any sub-task fails, the entire batch is reported as failed even though the other tasks actually ran.\n\n   2. Explain why it‚Äôs a problem\n     ‚Ä¢  You can‚Äôt see partial results or errors in real time.\n     ‚Ä¢  One failing branch masks useful output from the others, slowing triage and forcing retries.\n\n   3. Request the remedy\n     ‚Ä¢  Ask for streaming",
    "url": "https://github.com/Factory-AI/factory/issues/340",
    "timestamp": "2025-11-11T17:16:42Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 340
    }
  },
  {
    "id": "github_issue_337",
    "source": "github",
    "author": "etwk",
    "content": "[Issue] Make Copy Smooth\n\nDroid UI looks nice, but when I try to copy text to a editor to work further on it, there are some formatting issues:\n  - Frequent un-intended line breaks\n  - Empty space before each lines\n\nCan we make the transaction more smooth? It'll be huge UX enhancement.",
    "url": "https://github.com/Factory-AI/factory/issues/337",
    "timestamp": "2025-11-10T23:07:38Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 337
    }
  },
  {
    "id": "github_issue_335",
    "source": "github",
    "author": "etwk",
    "content": "[Issue] Subagent No Output\n\nTesting some subagents with the builtin models, the subagents seems running well but the main process never gets the output from the subagent task.\n\nUsing latest Droid (0.22.14) with the GPT-5-Codex model, getting this result:\n```\nAttempted to invoke the available subagents (code-reviewer, debugger) with simple greeting prompts, but each Task call returned ‚ÄúNo output received from task subagent,‚Äù so the requested ‚Äúhi‚Äù response could not be produced.\n```",
    "url": "https://github.com/Factory-AI/factory/issues/335",
    "timestamp": "2025-11-10T12:55:34Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 335
    }
  },
  {
    "id": "github_issue_334",
    "source": "github",
    "author": "etwk",
    "content": "[Issue] droid exec will change default model for the main process\n\nCurrently droid exec will change default model for the main process, maybe we should change this partly because of convenience, and partly because of process separation, not letting 2 unrelated process interfering in any possible way.",
    "url": "https://github.com/Factory-AI/factory/issues/334",
    "timestamp": "2025-11-10T12:42:52Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 334
    }
  },
  {
    "id": "github_issue_331",
    "source": "github",
    "author": "spionkind",
    "content": "[Issue] Issue with GPT5 Codex and Custom Model on Droid\n\n Hi,\n\nwhenever I chosed GPT5-codex model it show this error message:\nError: 400 Invalid 'tools[40].name': string too long. Expected a string with maximum length 64, but got a string with length 66 instead.\n\nand when I try with custom model (qwen3 coder), it shows this:\nError: 400 <400> InternalError.Algo.InvalidParameter: The length of the tool name cannot exceed 64.\n\nDroid still works well with other model suchas sonnet 4.5, glm 4.6\n\nPlease help me on this issues\n\nBest regards,\nGiang",
    "url": "https://github.com/Factory-AI/factory/issues/331",
    "timestamp": "2025-11-09T16:19:30Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 331
    }
  },
  {
    "id": "github_issue_330",
    "source": "github",
    "author": "olsavmic",
    "content": "[Issue] Feature Request: Implement Statusline Support\n\n  Add support for customizable statuslines in Factory's CLI interface, as documented in [Claude Code's statusline\n  feature](https://code.claude.com/docs/en/statusline).\n\n  Motivation\n\n  Statuslines provide persistent contextual information at the bottom of the interface, which is incredibly helpful for:\n   ‚Ä¢  Git awareness: Immediately see the current branch without running git status\n   ‚Ä¢  Directory context: Know your current working directory at a glance\n   ‚Ä¢  Session info: Display the curren",
    "url": "https://github.com/Factory-AI/factory/issues/330",
    "timestamp": "2025-11-09T11:34:21Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 330
    }
  },
  {
    "id": "reddit_1osf7sj",
    "source": "reddit",
    "author": "LittleChallenge8717",
    "content": "Custom Droid | Web search Task failed\n\nWeb search and calling custom droid feature in Droid not working, I use claude code inside droid (with CLIProxyAPI),\n\n(Neither works on openrouter models)\n\n\"\n\nWEB SEARCH  (\"current bitcoin price BTC USD\")\n\nSearch failed: Error: Error performing web search: Fetch failed\n\nWEB SEARCH  (\"ethereum ETH price USD current\")\n\nSearch failed: Error: Error performing web search: Fetch failed\n\n\"\n\n\" TASK  (mermaid-expert: \"Create system architecture diagram\")\n\n‚ö† Task failed\n\nTASK  (seo-meta-optimizer: \"Optimi",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1osf7sj/custom_droid_web_search_task_failed/",
    "timestamp": "2025-11-09T09:35:38.000Z",
    "metadata": {
      "score": 3,
      "num_comments": 3,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "github_issue_329",
    "source": "github",
    "author": "TheSingular",
    "content": "[Issue] Spec mode hides reasoning level effort in model name\n\nWhen using the spec mode, you cannot see the reasoning effort of the model you have selected (if it supports reasoning).\nYou can still change the reasoning effort via the tab key, but you cannot see its effect at all. Other modes properly display the reasoning effort in parentheses.\n\nHow to reproduce:\n1. Use model Sonnet 4.5 with low reasoning effort, do not choose a separate model for the spec model.\n2. Toggle to spec mode via ctrl + t.\n3. Observe the parentheses containing the reasoning effort",
    "url": "https://github.com/Factory-AI/factory/issues/329",
    "timestamp": "2025-11-09T09:12:43Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 329
    }
  },
  {
    "id": "github_issue_328",
    "source": "github",
    "author": "a112121788",
    "content": "[Issue] custom model support reasoning\n\n",
    "url": "https://github.com/Factory-AI/factory/issues/328",
    "timestamp": "2025-11-08T15:47:20Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 328
    }
  },
  {
    "id": "github_issue_325",
    "source": "github",
    "author": "Evan-Kim2028",
    "content": "[Issue] Task subagent runs tools but returns no final message (intermittent)\n\nSummary\n- Intermittently, Task executions succeed and run tools (Grep/Read/Glob/TodoWrite) but no final assistant message is emitted, and the wrapper surfaces: \"No output received from task subagent.\" This blocks using dbt droids for reviews.\n\nEnvironment\n- OS: macOS darwin 24.6.0\n- Factory CLI/session: latest as of 2025-11-07\n- Model: OpenAI GPT-5\n- gh: 2.80.0\n\nReproduction (today)\n1) Launch Task with subagent_type=\"dbt-quality-droid\" on local repo /Users/evandekim/Documents/spellbook (branch: ",
    "url": "https://github.com/Factory-AI/factory/issues/325",
    "timestamp": "2025-11-07T21:38:02Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 325
    }
  },
  {
    "id": "reddit_1or5cow",
    "source": "reddit",
    "author": "Durst123",
    "content": "What are the weekly limits in droid CLI?\n\nComparing it to Claude max.\n\nI hit the limits.",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1or5cow/what_are_the_weekly_limits_in_droid_cli/",
    "timestamp": "2025-11-07T20:29:10.000Z",
    "metadata": {
      "score": 1,
      "num_comments": 6,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "github_issue_321",
    "source": "github",
    "author": "nilzzzzzz",
    "content": "[Issue] Droid exec --output-format debug is not returning the result\n\nWe rely heavily on `droid exec` but since one of the last updates there is a huge issue. Running `droid exec --output-format debug` does not return anymore the result but just the debug outputs before:\n\nReproduction:\n\n```\ndroid exec \"which services does the backend have\" --output-format debug\n\n{\"type\":\"system\",\"subtype\":\"init\",\"cwd\":\"/Users/nilz/Repositories/awork-backend\",\"session_id\":\"273c1ae2-ffec-4ef5-b748-e04d713000fa\",\"tools\":[\"Read\",\"LS\",\"Execute\",\"Edit\",\"ApplyPatch\",\"Grep\",\"Glob\",\"Create",
    "url": "https://github.com/Factory-AI/factory/issues/321",
    "timestamp": "2025-11-07T12:11:44Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 321
    }
  },
  {
    "id": "github_issue_319",
    "source": "github",
    "author": "Bladed3d",
    "content": "[Issue] \"Endless Processing\" When using custom model openrouter: Grok-Code-Fast-1\n\nWhen using custom model openrouter: Grok-Code-Fast-1 after giving it a task, Droid will keep working on that until I press ESC then display context it has been building up. Upon further review, it seems that Droid using Grok is having a conversation with itself, forgetting to include me and wait for my actual participation:\n\n(This is just some of the context...)\n\nConfirming Dashboard Functionality\n   ‚Ä¢  The dashboard no longer shows duplicates, displaying only the current session's 1\n      root ",
    "url": "https://github.com/Factory-AI/factory/issues/319",
    "timestamp": "2025-11-06T20:19:04Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 319
    }
  },
  {
    "id": "github_issue_314",
    "source": "github",
    "author": "lifeisnphard",
    "content": "[Issue] File selector '@' not working in iTerm2\n\n## Environment\n- **OS**: macOS (darwin 25.0.0)\n- **Terminal**: iTerm2\n- **Factory CLI**: (version needs verification)\n- **Date**: 2025-11-04\n\n## Issue Description\nThe file selector feature triggered by the `@` symbol is not working in iTerm2. This functionality works correctly in Warp terminal but fails to appear in iTerm2.\n\n## Expected Behavior\nWhen typing `@` in the Factory Droid CLI interface, a file selector/picker UI should appear to allow interactive file selection, similar to the behavior",
    "url": "https://github.com/Factory-AI/factory/issues/314",
    "timestamp": "2025-11-04T19:12:02Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 314
    }
  },
  {
    "id": "github_discussion_309",
    "source": "github",
    "author": "msneijders",
    "content": "[Discussion] Droid CLI: configurable timeouts per mcp server\n\n**Motivation**: I use a 'Language Server Protocol' mcp for adding tools to query symbols and find_usage and such. But on large projects and during first-time use they can take quite some time before giving responses; causing timeouts in droid cli. If I could configure a larger timeout for this specific mcp server it could work better.",
    "url": "https://github.com/Factory-AI/factory/discussions/309",
    "timestamp": "2025-11-04T10:48:14Z",
    "metadata": {
      "type": "discussion",
      "category": "Feature requests",
      "number": 309
    }
  },
  {
    "id": "github_issue_308",
    "source": "github",
    "author": "Evan-Kim2028",
    "content": "[Issue] MCP servers configured globally aren‚Äôt exposed inside custom droid sessions (tools work in main interface, fail inside droid)\n\n## Summary\nMCP servers (dbt-mcp, igloo-mcp, github-mcp) are configured globally and work in the main interface, but their tools are not available when running inside a custom droid session. As a result, dbt/igloo/github MCP tool calls succeed outside the droid but fail inside the droid with messages indicating no MCP interface/tools.\n\n## Environment\n- OS: macOS 14.6 (24.6.0)\n- Shell: droid CLI (interactive)\n- Custom droid: `dbt_quality_droid` (personal droid)\n- MCP: servers registered globally (",
    "url": "https://github.com/Factory-AI/factory/issues/308",
    "timestamp": "2025-11-03T20:08:35Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 308
    }
  },
  {
    "id": "github_issue_301",
    "source": "github",
    "author": "nusquama",
    "content": "[Issue] How to configure Azure OpenAI with Factory CLI?\n\n\n\nHi\n\nI'm trying to configure Azure OpenAI (GPT-5 Codex) with Factory CLI using BYOK, but I can't find any documentation on how to properly set this up.\n\nI saw in the [[CLI Updates changelog](https://docs.factory.ai/changelog/cli-updates)](https://docs.factory.ai/changelog/cli-updates) that \"Azure OpenAI for GPT-5\" support was added, but there's no example configuration in the [[BYOK documentation](https://docs.factory.ai/cli/byok/overview)](https://docs.factory.ai/cli/byok/overview).\n\n**What I ",
    "url": "https://github.com/Factory-AI/factory/issues/301",
    "timestamp": "2025-11-02T10:10:24Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 301
    }
  },
  {
    "id": "github_issue_300",
    "source": "github",
    "author": "dpalfery",
    "content": "[Issue] Can't use standard c:\\git for root directory on windows\n\nFactory Bridge assumes that all windows developers put the git repos in c:\\users\\<user> but this is very rarely the case wtih expereinced professional developers. we use c:\\git or similar just as mac devs use \\home\\git . need to be able to change this with out adding a link.",
    "url": "https://github.com/Factory-AI/factory/issues/300",
    "timestamp": "2025-11-02T02:47:51Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 300
    }
  },
  {
    "id": "github_issue_298",
    "source": "github",
    "author": "tgerighty",
    "content": "[Issue] bug: droids using custom model with same name as a built-in model use the built-in model\n\nI have a number of droids defined and they all use the custom model defined in the droid. However, instead of using the custom model, they're being remapped to use the factory built-in model instead. This happens when your custom model has the same name as a factory model, which in my case I want to use my GLM-4.6 account with z.ai rather than using the factory model. \n\n**1. Droid Configuration Evidence (Custom Models Defined):**\n\ndroids/code-reviewer-droid-forge.md`\n\n   yaml\n     ---\n     name:",
    "url": "https://github.com/Factory-AI/factory/issues/298",
    "timestamp": "2025-11-01T16:36:44Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 298
    }
  },
  {
    "id": "github_discussion_240",
    "source": "github",
    "author": "factory-ben",
    "content": "[Discussion] Mini Changelog\n\n<img width=\"686\" height=\"397\" alt=\"Screenshot 2025-10-22 at 14 58 16\" src=\"https://github.com/user-attachments/assets/0288d87c-55b1-44b4-91cb-33d745fc052b\" />\r\n",
    "url": "https://github.com/Factory-AI/factory/discussions/240",
    "timestamp": "2025-10-23T09:45:14Z",
    "metadata": {
      "type": "discussion",
      "category": "Factory Official",
      "number": 240
    }
  },
  {
    "id": "github_discussion_225",
    "source": "github",
    "author": "JohnDotOwl",
    "content": "[Discussion] Change Log\n\nCan we have more updated change logs somewhere if possible. \r\n\r\nSuccessfully updated to version 0.21.5 Just saw this ",
    "url": "https://github.com/Factory-AI/factory/discussions/225",
    "timestamp": "2025-10-21T09:52:33Z",
    "metadata": {
      "type": "discussion",
      "category": "Feature requests",
      "number": 225
    }
  },
  {
    "id": "github_discussion_223",
    "source": "github",
    "author": "JohnDotOwl",
    "content": "[Discussion] [Discussion] Droid Exec Headless Streaming with output format (JSON)\n\nDroid Exec (Headless)\r\nIt make sense to use --output-format json if you're running a headless droid exec as that's the best way to programmatically manage the headless droid. The issue for me is i can't see the process and potentially stop it without --output-format debug and i can't run both output format. \r\n\r\nShould we consider having a different parameter for \"streaming\" , it's not so much for debugging but more to manage the task itself. ",
    "url": "https://github.com/Factory-AI/factory/discussions/223",
    "timestamp": "2025-10-21T02:46:01Z",
    "metadata": {
      "type": "discussion",
      "category": "Feature requests",
      "number": 223
    }
  },
  {
    "id": "github_discussion_214",
    "source": "github",
    "author": "0xStuart",
    "content": "[Discussion] JetBrains Plugin\n\nThe documentation says there is a JetBrains Plugin in the marketplace, but I can't find it.",
    "url": "https://github.com/Factory-AI/factory/discussions/214",
    "timestamp": "2025-10-19T19:55:35Z",
    "metadata": {
      "type": "discussion",
      "category": "Questions",
      "number": 214
    }
  },
  {
    "id": "github_discussion_164",
    "source": "github",
    "author": "tgerighty",
    "content": "[Discussion] Droid Exec - custom models supported?\n\ncan we have support for custom models in droid exec? even if it were just simple endpoint/key.",
    "url": "https://github.com/Factory-AI/factory/discussions/164",
    "timestamp": "2025-10-10T18:34:32Z",
    "metadata": {
      "type": "discussion",
      "category": "Feature requests",
      "number": 164
    }
  },
  {
    "id": "github_discussion_151",
    "source": "github",
    "author": "snowarch",
    "content": "[Discussion] Sound or notification when completed task\n\nIt would be useful to have some kind of sound or notification in the system when the agent has completed the task. Droid CLI, Arch Linux.",
    "url": "https://github.com/Factory-AI/factory/discussions/151",
    "timestamp": "2025-10-09T10:20:14Z",
    "metadata": {
      "type": "discussion",
      "category": "Feature requests",
      "number": 151
    }
  },
  {
    "id": "github_discussion_108",
    "source": "github",
    "author": "factory-ben",
    "content": "[Discussion] Release v1.3.220\n\n---\r\n\r\nThis release brings HTTP MCP server support, a `/compress` command to optimize your context usage and droid exec for CDE.\r\n\r\n---\r\n\r\n## HTTP MCP Server Support\r\n\r\nFactory now supports streamable HTTP-based Model Context Protocol (MCP) servers in addition to stdio-based servers. This enables you to connect to MCP servers running as web services, making it easier to integrate with cloud-hosted tools and services.\r\n\r\nWhen adding an MCP server, Factory automatically detects whether it's HTTP o",
    "url": "https://github.com/Factory-AI/factory/discussions/108",
    "timestamp": "2025-10-03T20:21:56Z",
    "metadata": {
      "type": "discussion",
      "category": "Factory Official",
      "number": 108
    }
  },
  {
    "id": "github_discussion_99",
    "source": "github",
    "author": "Evan-Kim2028",
    "content": "[Discussion] Droid source code\n\nIs droid closed source? I am not able to find any code. I would like to be able to see how the droid tools are implemented if the code is available to see",
    "url": "https://github.com/Factory-AI/factory/discussions/99",
    "timestamp": "2025-10-02T17:51:27Z",
    "metadata": {
      "type": "discussion",
      "category": "Questions",
      "number": 99
    }
  },
  {
    "id": "github_discussion_95",
    "source": "github",
    "author": "factory-ben",
    "content": "[Discussion] CLI v0.16.0 Release Notes\n\n- Sonnet 4.5 model is now available\r\n- Clear chat input using double ESC or Ctrl-C\r\n- User-configured allow and deny list of commands to execute\r\n- Option to disable droid commit co-authoring\r\n- Auth using FACTORY_API_KEY\r\n- Fixed UI bugs due to resizing",
    "url": "https://github.com/Factory-AI/factory/discussions/95",
    "timestamp": "2025-10-01T20:05:01Z",
    "metadata": {
      "type": "discussion",
      "category": "Factory Official",
      "number": 95
    }
  },
  {
    "id": "github_discussion_92",
    "source": "github",
    "author": "msneijders",
    "content": "[Discussion] MCP tools filtering\n\nI would like to configure exactly what tools of a MCP server should be made available.\r\n\r\nMotivation: MCP servers with overlapping functionality and too many unneeded tools is confusing the models.",
    "url": "https://github.com/Factory-AI/factory/discussions/92",
    "timestamp": "2025-10-01T09:07:33Z",
    "metadata": {
      "type": "discussion",
      "category": "Feature requests",
      "number": 92
    }
  },
  {
    "id": "github_discussion_82",
    "source": "github",
    "author": "mweichert",
    "content": "[Discussion] Web API?\n\nHi there! Is there a web API to create and manage sessions?",
    "url": "https://github.com/Factory-AI/factory/discussions/82",
    "timestamp": "2025-09-29T13:16:25Z",
    "metadata": {
      "type": "discussion",
      "category": "Questions",
      "number": 82
    }
  },
  {
    "id": "github_discussion_72",
    "source": "github",
    "author": "rubendn",
    "content": "[Discussion] Droid selection in CLI?\n\nIs there a way to use one of the specialized Droids (Product, Tutorial, etc) via the CLI?  I don't see a way to select in the slash commands.\r\n\r\nAlso, is there a way on Windows to select a local workspace path besides ~\\?\r\n\r\nThanks!",
    "url": "https://github.com/Factory-AI/factory/discussions/72",
    "timestamp": "2025-09-29T05:17:49Z",
    "metadata": {
      "type": "discussion",
      "category": "Questions",
      "number": 72
    }
  },
  {
    "id": "github_discussion_66",
    "source": "github",
    "author": "factory-ben",
    "content": "[Discussion] 2 new community builds: use claude/codex max subscriptions with droid\n\n- [Factory CLI with ChatGPT Codex / Claude subscription via CLIProxyAPI](https://gist.github.com/chandika/c4b64c5b8f5e29f6112021d46c159fdd) - Guide to run Factory CLI against Claude Code Max or ChatGPT Codex through CLIProxyAPI by [chandika](https://github.com/chandika)\r\n- [Factory CLI with Claude subscription via CLIProxyAPI](https://gist.github.com/ben-vargas/9f1a14ac5f78d10eba56be437b7c76e5) - Setup instructions for using Factory CLI with Claude Code Max through CLIProxyAPI by [ben-vargas](ht",
    "url": "https://github.com/Factory-AI/factory/discussions/66",
    "timestamp": "2025-09-27T19:15:40Z",
    "metadata": {
      "type": "discussion",
      "category": "Show + tell",
      "number": 66
    }
  },
  {
    "id": "github_discussion_65",
    "source": "github",
    "author": "jimkyndemeyer",
    "content": "[Discussion] BYOK with Anthropic models on Amazon Bedrock\n\nWould be great to have the option of using Amazon Bedrock for Anthropic models with BYOK.\r\n\r\nAnthropic has official SDKs for Bedrock, but the model env config is a bit different:\r\n- AWS region\r\n- Access key id\r\n- Secret access key",
    "url": "https://github.com/Factory-AI/factory/discussions/65",
    "timestamp": "2025-09-27T09:46:55Z",
    "metadata": {
      "type": "discussion",
      "category": "Feature requests",
      "number": 65
    }
  },
  {
    "id": "github_discussion_59",
    "source": "github",
    "author": "factory-ben",
    "content": "[Discussion] #1 on Terminal Bench\n\n<img width=\"1582\" height=\"972\" alt=\"Screenshot 2025-09-25 at 17 15 56\" src=\"https://github.com/user-attachments/assets/9e9c80b6-825c-41cc-b8c7-236b21e3f61c\" />\r\n\r\nRead how we did it: https://factory.ai/news/terminal-bench",
    "url": "https://github.com/Factory-AI/factory/discussions/59",
    "timestamp": "2025-09-25T19:22:25Z",
    "metadata": {
      "type": "discussion",
      "category": "Factory Official",
      "number": 59
    }
  },
  {
    "id": "github_discussion_32",
    "source": "github",
    "author": "factory-ben",
    "content": "[Discussion] CLI v0.7.0 Release Notes\n\nCLI Release (0.7.0)\r\n\r\n- Autonomy level selection: Users can now select any preferred autonomy level when confirming the ExitSpec tool\r\n- Claude reasoning support: Added support for Claude's reasoning capabilities\r\n- Session resumption: Users can now resume existing sessions when operating in Exec Mode\r\n- Image reading capabilities: The CLI can now read and process images",
    "url": "https://github.com/Factory-AI/factory/discussions/32",
    "timestamp": "2025-09-19T20:15:48Z",
    "metadata": {
      "type": "discussion",
      "category": "Factory Official",
      "number": 32
    }
  },
  {
    "id": "github_discussion_25",
    "source": "github",
    "author": "DannyAziz",
    "content": "[Discussion] Change model even if I've already written a prompt out\n\nSometimes I write a message, then realise I want to drop down to Sonnet, and I have to delete my message to hit the slash command. I wish there was a way to do this without deleting everything.",
    "url": "https://github.com/Factory-AI/factory/discussions/25",
    "timestamp": "2025-09-16T22:58:36Z",
    "metadata": {
      "type": "discussion",
      "category": "Feature requests",
      "number": 25
    }
  },
  {
    "id": "github_discussion_20",
    "source": "github",
    "author": "factory-ben",
    "content": "[Discussion] CLI v0.5.0 Release Notes\n\nv0.5 release:\r\n\r\n- Users can now queue messages while the Droid works\r\n- Added clearer autonomy level & mode descriptions\r\n- Fixed many flickering issues\r\n- Revamped `--help` command\r\n- Automatic VSCode / Cursor / Windsurf CLI detection,\r\n- Windows delete key bug fixed\r\n- Lots of small UI improvements\r\n- Lots of quality of life and bug fixes\n\ncoming soon:\n- custom droids/subagents\n- notif sounds\n- much more\n\nany requests? ",
    "url": "https://github.com/Factory-AI/factory/discussions/20",
    "timestamp": "2025-09-16T06:27:29Z",
    "metadata": {
      "type": "discussion",
      "category": "Factory Official",
      "number": 20
    }
  }
]