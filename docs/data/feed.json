[
  {
    "id": "twitter_1990281115224137784",
    "source": "twitter",
    "author": "GitMaxd",
    "content": "@EnoReyes @CloudTrader4 @FactoryAI Feels very close :) https://t.co/NdEUG0j2Gq",
    "url": "https://x.com/GitMaxd/status/1990281115224137784",
    "timestamp": "2025-11-17T04:49:30.000Z",
    "metadata": {
      "conversation_id": "1990281115224137784",
      "likes": 0,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1990271659002204338",
    "source": "twitter",
    "author": "EnoReyes",
    "content": "@CloudTrader4 @FactoryAI This feature is actually still in preview! Releasing soon :)",
    "url": "https://x.com/EnoReyes/status/1990271659002204338",
    "timestamp": "2025-11-17T04:11:55.000Z",
    "metadata": {
      "conversation_id": "1990271659002204338",
      "likes": 2,
      "retweets": 0,
      "replies": 1,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1990267822422077449",
    "source": "twitter",
    "author": "bheemreddy181",
    "content": "@steipete @FactoryAI So trimmy can copy directly from Ghostty?",
    "url": "https://x.com/bheemreddy181/status/1990267822422077449",
    "timestamp": "2025-11-17T03:56:40.000Z",
    "metadata": {
      "conversation_id": "1990267822422077449",
      "likes": 0,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1990266280792989706",
    "source": "twitter",
    "author": "steipete",
    "content": "@arimedai @FactoryAI And the ones that don't take 500MB :D",
    "url": "https://x.com/steipete/status/1990266280792989706",
    "timestamp": "2025-11-17T03:50:33.000Z",
    "metadata": {
      "conversation_id": "1990266280792989706",
      "likes": 1,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1990264256798003340",
    "source": "twitter",
    "author": "arimedai",
    "content": "@steipete @FactoryAI Handy. The best tools are the ones that quietly fix your daily annoyances.",
    "url": "https://x.com/arimedai/status/1990264256798003340",
    "timestamp": "2025-11-17T03:42:30.000Z",
    "metadata": {
      "conversation_id": "1990264256798003340",
      "likes": 0,
      "retweets": 0,
      "replies": 1,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1990261882771394925",
    "source": "twitter",
    "author": "erd0xbc",
    "content": "1) Plan/Spec mode @cursor_ai and @FactoryAI have the best approaches so far.\n2) More polished MCP tool management; e.g., after I add them, I should be able to disable/enable via /mcp\n3) Amp should know Amp settings.json (less relevant as you all are agent vs. model focused), so not much to tinker with.\n4) Not sure the right mental (agent) model, but how could GPT 5-1 Low or 5.1 Codex Med fit in?  GPT 5-1 Low feel like a drop in replacement for Sonnet 4.5 so far.\n4.1) GPT 5-1 Low is like a smarter rush while being cheaper*\n5) @FactoryAI used to have this issue, but its fixed now. Basically @AmpCode is primed for software engineering. If I prime Amp with knowledge of a custom cli, can it take that and run? Claude Code seems to be born for random things like that.\n6) Skills approach",
    "url": "https://x.com/erd0xbc/status/1990261882771394925",
    "timestamp": "2025-11-17T03:33:04.000Z",
    "metadata": {
      "conversation_id": "1990261882771394925",
      "likes": 1,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1990256155608957338",
    "source": "twitter",
    "author": "steipete",
    "content": "Trimmy now supports trimming these || borders, when you copy text from @FactoryAI - thanks to Blueemi! https://t.co/ikOH9Sqsyt https://t.co/L8pF327Kxb",
    "url": "https://x.com/steipete/status/1990256155608957338",
    "timestamp": "2025-11-17T03:10:19.000Z",
    "metadata": {
      "conversation_id": "1990256155608957338",
      "likes": 9,
      "retweets": 2,
      "replies": 3,
      "quotes": 1
    }
  },
  {
    "id": "twitter_1990253298574905839",
    "source": "twitter",
    "author": "martin_ict_algo",
    "content": "@CloudTrader4 @FactoryAI Mine doesnt even have /skills",
    "url": "https://x.com/martin_ict_algo/status/1990253298574905839",
    "timestamp": "2025-11-17T02:58:58.000Z",
    "metadata": {
      "conversation_id": "1990253298574905839",
      "likes": 0,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1990244517484839183",
    "source": "twitter",
    "author": "bheemreddy181",
    "content": "@CavalliniPosada @FactoryAI Have you tried the convex mcp with droid ?",
    "url": "https://x.com/bheemreddy181/status/1990244517484839183",
    "timestamp": "2025-11-17T02:24:04.000Z",
    "metadata": {
      "conversation_id": "1990244517484839183",
      "likes": 0,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1990227025093931196",
    "source": "twitter",
    "author": "momenabdelkarim",
    "content": "Been using Claude Code, Codex, and @FactoryAI Droid CLI with various models to do this migration and I‚Äôve noticed GPT 5/5.1 High in Codex has been the best for writing code in a @tan_stack Start (TSS) project. Codex does a much better job actually looking up the latest documentation for TSS, which is important for such a new framework as things change quickly. Otherwise it ends up writing a bunch of NextJS-like code and weird bugs start popping up. All these models don‚Äôt know much about TSS by default in their training dataset clearly.\n\nAlso I specify Codex because when I ran GPT 5/5.1 High in Droid CLI I was getting much lower quality output than via Codex.\n\nMake sure to set ‚Äúweb_search_request = true‚Äù in your Codex config.toml to ensure it can access the latest info! It‚Äôs off by default.",
    "url": "https://x.com/momenabdelkarim/status/1990227025093931196",
    "timestamp": "2025-11-17T01:14:34.000Z",
    "metadata": {
      "conversation_id": "1990227025093931196",
      "likes": 2,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "github_discussion_374",
    "source": "github",
    "author": "vibl",
    "content": "[Discussion] 20M tokens promised, 1M tokens received...\n\nThe website https://factorycli.com/ promises free 20M tokens. After clicking on the link and signing up, I only received 1M tokens . \r\n\r\nNot a good first impression...",
    "url": "https://github.com/Factory-AI/factory/discussions/374",
    "timestamp": "2025-11-17T00:05:46Z",
    "metadata": {
      "type": "discussion",
      "category": "General",
      "number": 374
    }
  },
  {
    "id": "reddit_1oz18qh",
    "source": "reddit",
    "author": "EggNo4904",
    "content": "not sure if i am the only one getting this, interestingly enough it had my card details saved tho.\n\nImages:\n\thttps://preview.redd.it/uu8xf048jp1g1.png?auto=webp&amp;s=9574291f2513a281eca97c75667653da65da086d\n",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1oz18qh/not_sure_if_i_am_the_only_one_getting_this/",
    "timestamp": "2025-11-16T23:56:02.000Z",
    "metadata": {
      "score": 2,
      "num_comments": 1,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "twitter_1990161948869300370",
    "source": "twitter",
    "author": "Mattslayga",
    "content": "@codewithimanshu @OpenAIDevs @FactoryAI I love updates when they actually stick",
    "url": "https://x.com/Mattslayga/status/1990161948869300370",
    "timestamp": "2025-11-16T20:55:58.000Z",
    "metadata": {
      "conversation_id": "1990161948869300370",
      "likes": 0,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1990159414850892064",
    "source": "twitter",
    "author": "TSpencer260",
    "content": "@hatchprop @ChrisVanDerKlau @FactoryAI Thank you!",
    "url": "https://x.com/TSpencer260/status/1990159414850892064",
    "timestamp": "2025-11-16T20:45:54.000Z",
    "metadata": {
      "conversation_id": "1990159414850892064",
      "likes": 0,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1990153744600948973",
    "source": "twitter",
    "author": "codewithimanshu",
    "content": "@pascallammers_ @FactoryAI @claudeai @OpenAI Absolutely, Pascal, I see your point, AI tools certainly offer an edge, but good ol' human touch is still crucial, no?",
    "url": "https://x.com/codewithimanshu/status/1990153744600948973",
    "timestamp": "2025-11-16T20:23:22.000Z",
    "metadata": {
      "conversation_id": "1990153744600948973",
      "likes": 0,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1990153224859611559",
    "source": "twitter",
    "author": "codewithimanshu",
    "content": "@AdhamAlkhaja @FactoryAI Wow, Adham, that's a significant difference! It's either super quick, or maybe something's being missed, right?",
    "url": "https://x.com/codewithimanshu/status/1990153224859611559",
    "timestamp": "2025-11-16T20:21:18.000Z",
    "metadata": {
      "conversation_id": "1990153224859611559",
      "likes": 0,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1990152118741967212",
    "source": "twitter",
    "author": "a2a_2030",
    "content": "@AdhamAlkhaja @FactoryAI ampcode",
    "url": "https://x.com/a2a_2030/status/1990152118741967212",
    "timestamp": "2025-11-16T20:16:55.000Z",
    "metadata": {
      "conversation_id": "1990152118741967212",
      "likes": 0,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1990150840133554547",
    "source": "twitter",
    "author": "hatchprop",
    "content": "@TSpencer260 @ChrisVanDerKlau @FactoryAI Ccusage",
    "url": "https://x.com/hatchprop/status/1990150840133554547",
    "timestamp": "2025-11-16T20:11:50.000Z",
    "metadata": {
      "conversation_id": "1990150840133554547",
      "likes": 1,
      "retweets": 0,
      "replies": 1,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1990150322271191365",
    "source": "twitter",
    "author": "codewithimanshu",
    "content": "@Mattslayga @OpenAIDevs @FactoryAI Arey, Slayga, you're right, it's a bit of a letdown seeing those OpenAI updates, isn't it? Back to the grind then!",
    "url": "https://x.com/codewithimanshu/status/1990150322271191365",
    "timestamp": "2025-11-16T20:09:46.000Z",
    "metadata": {
      "conversation_id": "1990150322271191365",
      "likes": 0,
      "retweets": 0,
      "replies": 1,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1990148463472869699",
    "source": "twitter",
    "author": "TSpencer260",
    "content": "@hatchprop @ChrisVanDerKlau @FactoryAI How are you able to see this data?",
    "url": "https://x.com/TSpencer260/status/1990148463472869699",
    "timestamp": "2025-11-16T20:02:23.000Z",
    "metadata": {
      "conversation_id": "1990148463472869699",
      "likes": 0,
      "retweets": 0,
      "replies": 1,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1990148458821615753",
    "source": "twitter",
    "author": "SynthSquid",
    "content": "@FactoryAI Can you make more benchmark visuals, and test GPT-5.1-Codex-Mini, and MiniMax: MiniMax M2,  these were amazing https://t.co/9Ael0B8tLv",
    "url": "https://x.com/SynthSquid/status/1990148458821615753",
    "timestamp": "2025-11-16T20:02:22.000Z",
    "metadata": {
      "conversation_id": "1990148458821615753",
      "likes": 2,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "twitter_1990144843499311498",
    "source": "twitter",
    "author": "ben_vargas",
    "content": "@immoinulmoin @FactoryAI And in case anyone notices, yes, I fixed the permissions on that one file to 600 :)",
    "url": "https://x.com/ben_vargas/status/1990144843499311498",
    "timestamp": "2025-11-16T19:48:00.000Z",
    "metadata": {
      "conversation_id": "1990144843499311498",
      "likes": 0,
      "retweets": 0,
      "replies": 0,
      "quotes": 0
    }
  },
  {
    "id": "reddit_1oys5f5",
    "source": "reddit",
    "author": "SensitiveUpstairs803",
    "content": "Fix large file parsing crash issue.\n\nIf we have a large file Droid's file view tool will try to parse it and then crash because the file is to large but to solve the crashing you should add something that detects the size of the file then if its too large it will resort to using a powershell command instead of the built in droid file parser tool to parse a few lines of the file to get the format etc based on whatever the question involving the file is. Simple feature simple fix.",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1oys5f5/fix_large_file_parsing_crash_issue/",
    "timestamp": "2025-11-16T17:50:18.000Z",
    "metadata": {
      "score": 2,
      "num_comments": 0,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "reddit_1oydnzt",
    "source": "reddit",
    "author": "EggNo4904",
    "content": "When i put my real number this is what i get ( i moved it out, also the pretty print some vercel blocks heard a lot of droid would love to be able to try it)\n\nImages:\n\thttps://preview.redd.it/huzzfboe3k1g1.png?auto=webp&amp;s=f342b5e1a1ba7e0c301f58a658fd42ac56fe6535\n",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1oydnzt/when_i_put_my_real_number_this_is_what_i_get_i/",
    "timestamp": "2025-11-16T05:38:43.000Z",
    "metadata": {
      "score": 2,
      "num_comments": 4,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "github_issue_372",
    "source": "github",
    "author": "presidentoor",
    "content": "[Issue] Done Shield Disablement\n\nWhen unchecking the Drone Shield button and clicking save, the system responds with an error that it fails to disable the drone shield.",
    "url": "https://github.com/Factory-AI/factory/issues/372",
    "timestamp": "2025-11-15T21:48:31Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 372
    }
  },
  {
    "id": "github_issue_371",
    "source": "github",
    "author": "presidentoor",
    "content": "[Issue] Support Button Doesn't Work\n\nWhen logged in at app.factory.ai the drop down on the right with the support link, doesn't do anything.",
    "url": "https://github.com/Factory-AI/factory/issues/371",
    "timestamp": "2025-11-15T21:47:24Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 371
    }
  },
  {
    "id": "github_issue_370",
    "source": "github",
    "author": "aranej",
    "content": "[Issue] UserPromptSubmit hook stdout not injected into LLM context\n\n## Problem\n\nUserPromptSubmit hooks execute successfully but their stdout is not injected into the LLM context, despite [documentation](https://github.com/Factory-AI/factory/blob/main/docs/reference/hooks-reference.mdx#userpromptsubmit-decision-control) stating it should be.\n\n**Expected:** Hook stdout added to context before prompt processing  \n**Actual:** Hook runs, outputs to stdout, but LLM never receives it\n\n## Evidence\n\nDebug logging proves hook execution:\n\n```\n[2025-11-15 16:16:05.140072] U",
    "url": "https://github.com/Factory-AI/factory/issues/370",
    "timestamp": "2025-11-15T15:36:30Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 370
    }
  },
  {
    "id": "github_issue_369",
    "source": "github",
    "author": "BlackCatCmx",
    "content": "[Issue] The .factory/skills directory is created even when \"enableSkills\": false is set\n\nI have set \"enableSkills\": false in the settings.json, but every time droid starts it still automatically creates the .factory/skills directory.\n\nIs this expected behavior (e.g. I misunderstood how to configure it), or is this setting not intended to prevent the creation of the skills directory, or could this be a bug?",
    "url": "https://github.com/Factory-AI/factory/issues/369",
    "timestamp": "2025-11-15T14:38:14Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 369
    }
  },
  {
    "id": "github_issue_366",
    "source": "github",
    "author": "nikolas-sturm",
    "content": "[Issue] Extension not working in WSL\n\nHi, my usual setup consists of VSC connecting to WSL Debian where all my projects reside. The Claude Code extension for VSC works perfectly fine in this setup, however I found that the droid extension is not recognized by the CLI when a WSL workspace is open. It instantly starts working when i open the windows native droid CLI in a non WSL workspace in VSC. I also found that trying to install the extension through the `/settings` menu simply fails when inside WSL. ",
    "url": "https://github.com/Factory-AI/factory/issues/366",
    "timestamp": "2025-11-15T11:29:55Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 366
    }
  },
  {
    "id": "reddit_1oxk7bb",
    "source": "reddit",
    "author": "EggNo4904",
    "content": "Anybody else getting the pretty-print? vercel security etc. dk why it wont accept my card.\n\nThumbnail: self\n",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1oxk7bb/anybody_else_getting_the_prettyprint_vercel/",
    "timestamp": "2025-11-15T06:07:46.000Z",
    "metadata": {
      "score": 3,
      "num_comments": 3,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "reddit_1ox98ue",
    "source": "reddit",
    "author": "bentossell",
    "content": "Changelog: v0.26.0\n\n**New features**\n\n‚Ä¢ Session Favorites: New /favorite command to pin/unpin sessions, keeping your active projects at the top of the session list\n\n‚Ä¢ Enhanced Bug Reporting: The /bug command now zips session context, uploads it to Factory, and returns a shareable report ID automatically\n\n‚Ä¢ Cleaner Diff Viewer: Improved UI with horizontal lines instead of borders\n\n\n\n**Bug fixes &amp; smaller items**\n\n‚Ä¢ Always prompt to accept or reject generated specs and pass the correct labels to the UI flow\n\n‚Ä¢ dr",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1ox98ue/changelog_v0260/",
    "timestamp": "2025-11-14T21:33:18.000Z",
    "metadata": {
      "score": 7,
      "num_comments": 10,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "github_discussion_361",
    "source": "github",
    "author": "aaronschwartz",
    "content": "[Discussion] Does using the CLI in BYOK mode send data to Factory.ai?\n\nIf we configure the cli to use our own model through BYOK, does any of our data get sent to Factory.ai servers before being submitted to the model for processing? e.g. is there any codebase indexing or embedding being created by Factory.ai in the cloud before prompting the BYOK third party providers?",
    "url": "https://github.com/Factory-AI/factory/discussions/361",
    "timestamp": "2025-11-14T21:17:40Z",
    "metadata": {
      "type": "discussion",
      "category": "Questions",
      "number": 361
    }
  },
  {
    "id": "github_issue_360",
    "source": "github",
    "author": "hanlin-luo",
    "content": "[Issue] CJK double-width characters problem\n\nChinese input (CJK double-width characters) causes cursor misalignment once the input spans more than two lines.\nThis is due to the line editor not correctly implementing Unicode East Asian Width, resulting in incorrect wcwidth calculationsÔºåÔºàmaybeÔºâ.\nIt‚Äôs recommended to enable or fix proper wide-character support in the TUI/line editor being used.\n\nhttps://github.com/user-attachments/assets/7be46a43-0fe3-4e76-98c0-bea3727137e3",
    "url": "https://github.com/Factory-AI/factory/issues/360",
    "timestamp": "2025-11-14T20:31:10Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 360
    }
  },
  {
    "id": "reddit_1ox6p07",
    "source": "reddit",
    "author": "ShipSpecialist6727",
    "content": "Being charge for all limit overage while having credit balance\n\nhttps://preview.redd.it/apq9eqc22a1g1.png?width=713&amp;format=png&amp;auto=webp&amp;s=b55698314d83f7e933e7c750576ab10285a54f3a\n\nhttps://preview.redd.it/c4n0ms032a1g1.png?width=1088&amp;format=png&amp;auto=webp&amp;s=4c124b65440a28c118b9d8a714f0da7618eaf4aa\n\nhttps://preview.redd.it/h2scb4072a1g1.png?width=1226&amp;format=png&amp;auto=webp&amp;s=7fbc4d224122903a737d9f9b4ed0c2092e03ce72\n\n  \nI'm being charge for 40$ limit overage while having my credit balance from my referral .  \nThe support is to",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1ox6p07/being_charge_for_all_limit_overage_while_having/",
    "timestamp": "2025-11-14T19:54:09.000Z",
    "metadata": {
      "score": 3,
      "num_comments": 2,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "reddit_1owv5gf",
    "source": "reddit",
    "author": "bentossell",
    "content": "how to set up custom models with Groq in &lt;1 min\n\nhttps://reddit.com/link/1owv5gf/video/vfpxccohu71g1/player\n\nvideo above  \ndocs: [https://docs.factory.ai/cli/byok/groq](https://docs.factory.ai/cli/byok/groq)",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1owv5gf/how_to_set_up_custom_models_with_groq_in_1_min/",
    "timestamp": "2025-11-14T12:27:05.000Z",
    "metadata": {
      "score": 1,
      "num_comments": 0,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "reddit_1owpdgs",
    "source": "reddit",
    "author": "Informal-Spinach-345",
    "content": "Todo list with minimax m2\n\nAny one else have issues with Minimax M2 on vllm not being able to properly use the todo list? \n\n  \nThis is what the output looks like, it eventually moves on but I never see a todo list:\n\n   Let me create a comprehensive todo list that captures all the remaining work.\n\n   &lt;/think&gt;\n\n\n\n\n\n\n\n\n\n‚õ¨  &lt;think&gt;I need to fix the todo format - the todos parameter should be an array, not an object.\n\n   &lt;/think&gt;\n\n\n\n\n\n\n\n\n\n‚õ¨  &lt;think&gt;Let me check the todo structure more carefully. Looking",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1owpdgs/todo_list_with_minimax_m2/",
    "timestamp": "2025-11-14T06:41:19.000Z",
    "metadata": {
      "score": 1,
      "num_comments": 8,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "reddit_1owbvoj",
    "source": "reddit",
    "author": "bentossell",
    "content": "How should we post changelogs here?\n\nhey, i'm ben - dev rel at factory. you may have seen me answering comments.\n\nwe have a changelog now but has like 4/5 updates a week. its automated as a bot in our discord channel. \n\nshould we add anything here? if so, what format is best?",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1owbvoj/how_should_we_post_changelogs_here/",
    "timestamp": "2025-11-13T20:22:54.000Z",
    "metadata": {
      "score": 7,
      "num_comments": 4,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "reddit_1ow4spq",
    "source": "reddit",
    "author": "Rough-Aioli-7829",
    "content": "Why I can't register my email?\n\nImages:\n\thttps://preview.redd.it/rgbm3fcdr11g1.png?auto=webp&amp;s=b0a9871d3d6836057ca15067a94c8a71463ae5ca\n",
    "url": "https://www.reddit.com/r/FactoryAi/comments/1ow4spq/why_i_cant_register_my_email/",
    "timestamp": "2025-11-13T15:58:33.000Z",
    "metadata": {
      "score": 2,
      "num_comments": 1,
      "subreddit": "FactoryAi"
    }
  },
  {
    "id": "github_issue_348",
    "source": "github",
    "author": "aranej",
    "content": "[Issue] üöÄ Feature Request: Native Task Queue Support for Interactive Mode\n\n## üìã Summary\n\nRequest for **native task queuing functionality** in Droid CLI interactive mode, allowing users to queue multiple prompts for sequential or parallel processing without waiting for each task to complete before submitting the next one.\n\n## üéØ Problem Statement\n\n### Current User Experience (Frustrating)\n\n```bash\n> /sys-info is running...\n[User types: /init-prompt]\n‚ùå Command doesn't register - must wait for completion\n\n[After 30 seconds...]\n‚úÖ /sys-info completed\n\n[User must now re-typ",
    "url": "https://github.com/Factory-AI/factory/issues/348",
    "timestamp": "2025-11-13T09:01:07Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 348
    }
  },
  {
    "id": "github_issue_345",
    "source": "github",
    "author": "xianzou",
    "content": "[Issue] Running dorid in PowerShell produces no output\n\n<img width=\"1113\" height=\"626\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/0bddc80a-404e-4fee-9575-96c0cdc89b94\" />\n\nRunning dorid in PowerShell produces no outputÔºåI have already installed dorid.",
    "url": "https://github.com/Factory-AI/factory/issues/345",
    "timestamp": "2025-11-13T01:46:56Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 345
    }
  },
  {
    "id": "github_issue_341",
    "source": "github",
    "author": "580ai",
    "content": "[Issue] droidÔºöIt seems that the maximum output tokens will not be outputted anymore once they reach 8192\n\nIt will suddenly terminate and then remain stuck without returning any content until the maximum timeout is reached",
    "url": "https://github.com/Factory-AI/factory/issues/341",
    "timestamp": "2025-11-12T08:46:22Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 341
    }
  },
  {
    "id": "github_issue_340",
    "source": "github",
    "author": "korallis",
    "content": "[Issue] Multi Agent Issues in regards to aggrigated RPC\n\n 1. Describe the behavior\n     ‚Ä¢  When you invoke multiple tools via the parallel wrapper, you get no output until every sub-task completes.\n     ‚Ä¢  If any sub-task fails, the entire batch is reported as failed even though the other tasks actually ran.\n\n   2. Explain why it‚Äôs a problem\n     ‚Ä¢  You can‚Äôt see partial results or errors in real time.\n     ‚Ä¢  One failing branch masks useful output from the others, slowing triage and forcing retries.\n\n   3. Request the remedy\n     ‚Ä¢  Ask for streaming",
    "url": "https://github.com/Factory-AI/factory/issues/340",
    "timestamp": "2025-11-11T17:16:42Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 340
    }
  },
  {
    "id": "github_issue_337",
    "source": "github",
    "author": "etwk",
    "content": "[Issue] Make Copy Smooth\n\nDroid UI looks nice, but when I try to copy text to a editor to work further on it, there are some formatting issues:\n  - Frequent un-intended line breaks\n  - Empty space before each lines\n\nCan we make the transaction more smooth? It'll be huge UX enhancement.",
    "url": "https://github.com/Factory-AI/factory/issues/337",
    "timestamp": "2025-11-10T23:07:38Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 337
    }
  },
  {
    "id": "github_issue_335",
    "source": "github",
    "author": "etwk",
    "content": "[Issue] Subagent No Output\n\nTesting some subagents with the builtin models, the subagents seems running well but the main process never gets the output from the subagent task.\n\nUsing latest Droid (0.22.14) with the GPT-5-Codex model, getting this result:\n```\nAttempted to invoke the available subagents (code-reviewer, debugger) with simple greeting prompts, but each Task call returned ‚ÄúNo output received from task subagent,‚Äù so the requested ‚Äúhi‚Äù response could not be produced.\n```",
    "url": "https://github.com/Factory-AI/factory/issues/335",
    "timestamp": "2025-11-10T12:55:34Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 335
    }
  },
  {
    "id": "github_issue_334",
    "source": "github",
    "author": "etwk",
    "content": "[Issue] droid exec will change default model for the main process\n\nCurrently droid exec will change default model for the main process, maybe we should change this partly because of convenience, and partly because of process separation, not letting 2 unrelated process interfering in any possible way.",
    "url": "https://github.com/Factory-AI/factory/issues/334",
    "timestamp": "2025-11-10T12:42:52Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 334
    }
  },
  {
    "id": "github_issue_331",
    "source": "github",
    "author": "spionkind",
    "content": "[Issue] Issue with GPT5 Codex and Custom Model on Droid\n\n Hi,\n\nwhenever I chosed GPT5-codex model it show this error message:\nError: 400 Invalid 'tools[40].name': string too long. Expected a string with maximum length 64, but got a string with length 66 instead.\n\nand when I try with custom model (qwen3 coder), it shows this:\nError: 400 <400> InternalError.Algo.InvalidParameter: The length of the tool name cannot exceed 64.\n\nDroid still works well with other model suchas sonnet 4.5, glm 4.6\n\nPlease help me on this issues\n\nBest regards,\nGiang",
    "url": "https://github.com/Factory-AI/factory/issues/331",
    "timestamp": "2025-11-09T16:19:30Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 331
    }
  },
  {
    "id": "github_issue_330",
    "source": "github",
    "author": "olsavmic",
    "content": "[Issue] Feature Request: Implement Statusline Support\n\n  Add support for customizable statuslines in Factory's CLI interface, as documented in [Claude Code's statusline\n  feature](https://code.claude.com/docs/en/statusline).\n\n  Motivation\n\n  Statuslines provide persistent contextual information at the bottom of the interface, which is incredibly helpful for:\n   ‚Ä¢  Git awareness: Immediately see the current branch without running git status\n   ‚Ä¢  Directory context: Know your current working directory at a glance\n   ‚Ä¢  Session info: Display the curren",
    "url": "https://github.com/Factory-AI/factory/issues/330",
    "timestamp": "2025-11-09T11:34:21Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 330
    }
  },
  {
    "id": "github_issue_329",
    "source": "github",
    "author": "TheSingular",
    "content": "[Issue] Spec mode hides reasoning level effort in model name\n\nWhen using the spec mode, you cannot see the reasoning effort of the model you have selected (if it supports reasoning).\nYou can still change the reasoning effort via the tab key, but you cannot see its effect at all. Other modes properly display the reasoning effort in parentheses.\n\nHow to reproduce:\n1. Use model Sonnet 4.5 with low reasoning effort, do not choose a separate model for the spec model.\n2. Toggle to spec mode via ctrl + t.\n3. Observe the parentheses containing the reasoning effort",
    "url": "https://github.com/Factory-AI/factory/issues/329",
    "timestamp": "2025-11-09T09:12:43Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 329
    }
  },
  {
    "id": "github_issue_328",
    "source": "github",
    "author": "a112121788",
    "content": "[Issue] custom model support reasoning\n\n",
    "url": "https://github.com/Factory-AI/factory/issues/328",
    "timestamp": "2025-11-08T15:47:20Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 328
    }
  },
  {
    "id": "github_issue_325",
    "source": "github",
    "author": "Evan-Kim2028",
    "content": "[Issue] Task subagent runs tools but returns no final message (intermittent)\n\nSummary\n- Intermittently, Task executions succeed and run tools (Grep/Read/Glob/TodoWrite) but no final assistant message is emitted, and the wrapper surfaces: \"No output received from task subagent.\" This blocks using dbt droids for reviews.\n\nEnvironment\n- OS: macOS darwin 24.6.0\n- Factory CLI/session: latest as of 2025-11-07\n- Model: OpenAI GPT-5\n- gh: 2.80.0\n\nReproduction (today)\n1) Launch Task with subagent_type=\"dbt-quality-droid\" on local repo /Users/evandekim/Documents/spellbook (branch: ",
    "url": "https://github.com/Factory-AI/factory/issues/325",
    "timestamp": "2025-11-07T21:38:02Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 325
    }
  },
  {
    "id": "github_issue_321",
    "source": "github",
    "author": "nilzzzzzz",
    "content": "[Issue] Droid exec --output-format debug is not returning the result\n\nWe rely heavily on `droid exec` but since one of the last updates there is a huge issue. Running `droid exec --output-format debug` does not return anymore the result but just the debug outputs before:\n\nReproduction:\n\n```\ndroid exec \"which services does the backend have\" --output-format debug\n\n{\"type\":\"system\",\"subtype\":\"init\",\"cwd\":\"/Users/nilz/Repositories/awork-backend\",\"session_id\":\"273c1ae2-ffec-4ef5-b748-e04d713000fa\",\"tools\":[\"Read\",\"LS\",\"Execute\",\"Edit\",\"ApplyPatch\",\"Grep\",\"Glob\",\"Create",
    "url": "https://github.com/Factory-AI/factory/issues/321",
    "timestamp": "2025-11-07T12:11:44Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 321
    }
  },
  {
    "id": "github_issue_319",
    "source": "github",
    "author": "Bladed3d",
    "content": "[Issue] \"Endless Processing\" When using custom model openrouter: Grok-Code-Fast-1\n\nWhen using custom model openrouter: Grok-Code-Fast-1 after giving it a task, Droid will keep working on that until I press ESC then display context it has been building up. Upon further review, it seems that Droid using Grok is having a conversation with itself, forgetting to include me and wait for my actual participation:\n\n(This is just some of the context...)\n\nConfirming Dashboard Functionality\n   ‚Ä¢  The dashboard no longer shows duplicates, displaying only the current session's 1\n      root ",
    "url": "https://github.com/Factory-AI/factory/issues/319",
    "timestamp": "2025-11-06T20:19:04Z",
    "metadata": {
      "type": "issue",
      "labels": [],
      "number": 319
    }
  },
  {
    "id": "github_discussion_309",
    "source": "github",
    "author": "msneijders",
    "content": "[Discussion] Droid CLI: configurable timeouts per mcp server\n\n**Motivation**: I use a 'Language Server Protocol' mcp for adding tools to query symbols and find_usage and such. But on large projects and during first-time use they can take quite some time before giving responses; causing timeouts in droid cli. If I could configure a larger timeout for this specific mcp server it could work better.",
    "url": "https://github.com/Factory-AI/factory/discussions/309",
    "timestamp": "2025-11-04T10:48:14Z",
    "metadata": {
      "type": "discussion",
      "category": "Feature requests",
      "number": 309
    }
  },
  {
    "id": "github_discussion_240",
    "source": "github",
    "author": "factory-ben",
    "content": "[Discussion] Mini Changelog\n\n<img width=\"686\" height=\"397\" alt=\"Screenshot 2025-10-22 at 14 58 16\" src=\"https://github.com/user-attachments/assets/0288d87c-55b1-44b4-91cb-33d745fc052b\" />\r\n",
    "url": "https://github.com/Factory-AI/factory/discussions/240",
    "timestamp": "2025-10-23T09:45:14Z",
    "metadata": {
      "type": "discussion",
      "category": "Factory Official",
      "number": 240
    }
  },
  {
    "id": "github_discussion_225",
    "source": "github",
    "author": "JohnDotOwl",
    "content": "[Discussion] Change Log\n\nCan we have more updated change logs somewhere if possible. \r\n\r\nSuccessfully updated to version 0.21.5 Just saw this ",
    "url": "https://github.com/Factory-AI/factory/discussions/225",
    "timestamp": "2025-10-21T09:52:33Z",
    "metadata": {
      "type": "discussion",
      "category": "Feature requests",
      "number": 225
    }
  },
  {
    "id": "github_discussion_223",
    "source": "github",
    "author": "JohnDotOwl",
    "content": "[Discussion] [Discussion] Droid Exec Headless Streaming with output format (JSON)\n\nDroid Exec (Headless)\r\nIt make sense to use --output-format json if you're running a headless droid exec as that's the best way to programmatically manage the headless droid. The issue for me is i can't see the process and potentially stop it without --output-format debug and i can't run both output format. \r\n\r\nShould we consider having a different parameter for \"streaming\" , it's not so much for debugging but more to manage the task itself. ",
    "url": "https://github.com/Factory-AI/factory/discussions/223",
    "timestamp": "2025-10-21T02:46:01Z",
    "metadata": {
      "type": "discussion",
      "category": "Feature requests",
      "number": 223
    }
  },
  {
    "id": "github_discussion_214",
    "source": "github",
    "author": "0xStuart",
    "content": "[Discussion] JetBrains Plugin\n\nThe documentation says there is a JetBrains Plugin in the marketplace, but I can't find it.",
    "url": "https://github.com/Factory-AI/factory/discussions/214",
    "timestamp": "2025-10-19T19:55:35Z",
    "metadata": {
      "type": "discussion",
      "category": "Questions",
      "number": 214
    }
  },
  {
    "id": "github_discussion_164",
    "source": "github",
    "author": "tgerighty",
    "content": "[Discussion] Droid Exec - custom models supported?\n\ncan we have support for custom models in droid exec? even if it were just simple endpoint/key.",
    "url": "https://github.com/Factory-AI/factory/discussions/164",
    "timestamp": "2025-10-10T18:34:32Z",
    "metadata": {
      "type": "discussion",
      "category": "Feature requests",
      "number": 164
    }
  },
  {
    "id": "github_discussion_151",
    "source": "github",
    "author": "snowarch",
    "content": "[Discussion] Sound or notification when completed task\n\nIt would be useful to have some kind of sound or notification in the system when the agent has completed the task. Droid CLI, Arch Linux.",
    "url": "https://github.com/Factory-AI/factory/discussions/151",
    "timestamp": "2025-10-09T10:20:14Z",
    "metadata": {
      "type": "discussion",
      "category": "Feature requests",
      "number": 151
    }
  },
  {
    "id": "github_discussion_108",
    "source": "github",
    "author": "factory-ben",
    "content": "[Discussion] Release v1.3.220\n\n---\r\n\r\nThis release brings HTTP MCP server support, a `/compress` command to optimize your context usage and droid exec for CDE.\r\n\r\n---\r\n\r\n## HTTP MCP Server Support\r\n\r\nFactory now supports streamable HTTP-based Model Context Protocol (MCP) servers in addition to stdio-based servers. This enables you to connect to MCP servers running as web services, making it easier to integrate with cloud-hosted tools and services.\r\n\r\nWhen adding an MCP server, Factory automatically detects whether it's HTTP o",
    "url": "https://github.com/Factory-AI/factory/discussions/108",
    "timestamp": "2025-10-03T20:21:56Z",
    "metadata": {
      "type": "discussion",
      "category": "Factory Official",
      "number": 108
    }
  },
  {
    "id": "github_discussion_99",
    "source": "github",
    "author": "Evan-Kim2028",
    "content": "[Discussion] Droid source code\n\nIs droid closed source? I am not able to find any code. I would like to be able to see how the droid tools are implemented if the code is available to see",
    "url": "https://github.com/Factory-AI/factory/discussions/99",
    "timestamp": "2025-10-02T17:51:27Z",
    "metadata": {
      "type": "discussion",
      "category": "Questions",
      "number": 99
    }
  },
  {
    "id": "github_discussion_95",
    "source": "github",
    "author": "factory-ben",
    "content": "[Discussion] CLI v0.16.0 Release Notes\n\n- Sonnet 4.5 model is now available\r\n- Clear chat input using double ESC or Ctrl-C\r\n- User-configured allow and deny list of commands to execute\r\n- Option to disable droid commit co-authoring\r\n- Auth using FACTORY_API_KEY\r\n- Fixed UI bugs due to resizing",
    "url": "https://github.com/Factory-AI/factory/discussions/95",
    "timestamp": "2025-10-01T20:05:01Z",
    "metadata": {
      "type": "discussion",
      "category": "Factory Official",
      "number": 95
    }
  },
  {
    "id": "github_discussion_92",
    "source": "github",
    "author": "msneijders",
    "content": "[Discussion] MCP tools filtering\n\nI would like to configure exactly what tools of a MCP server should be made available.\r\n\r\nMotivation: MCP servers with overlapping functionality and too many unneeded tools is confusing the models.",
    "url": "https://github.com/Factory-AI/factory/discussions/92",
    "timestamp": "2025-10-01T09:07:33Z",
    "metadata": {
      "type": "discussion",
      "category": "Feature requests",
      "number": 92
    }
  },
  {
    "id": "github_discussion_82",
    "source": "github",
    "author": "mweichert",
    "content": "[Discussion] Web API?\n\nHi there! Is there a web API to create and manage sessions?",
    "url": "https://github.com/Factory-AI/factory/discussions/82",
    "timestamp": "2025-09-29T13:16:25Z",
    "metadata": {
      "type": "discussion",
      "category": "Questions",
      "number": 82
    }
  },
  {
    "id": "github_discussion_72",
    "source": "github",
    "author": "rubendn",
    "content": "[Discussion] Droid selection in CLI?\n\nIs there a way to use one of the specialized Droids (Product, Tutorial, etc) via the CLI?  I don't see a way to select in the slash commands.\r\n\r\nAlso, is there a way on Windows to select a local workspace path besides ~\\?\r\n\r\nThanks!",
    "url": "https://github.com/Factory-AI/factory/discussions/72",
    "timestamp": "2025-09-29T05:17:49Z",
    "metadata": {
      "type": "discussion",
      "category": "Questions",
      "number": 72
    }
  },
  {
    "id": "github_discussion_66",
    "source": "github",
    "author": "factory-ben",
    "content": "[Discussion] 2 new community builds: use claude/codex max subscriptions with droid\n\n- [Factory CLI with ChatGPT Codex / Claude subscription via CLIProxyAPI](https://gist.github.com/chandika/c4b64c5b8f5e29f6112021d46c159fdd) - Guide to run Factory CLI against Claude Code Max or ChatGPT Codex through CLIProxyAPI by [chandika](https://github.com/chandika)\r\n- [Factory CLI with Claude subscription via CLIProxyAPI](https://gist.github.com/ben-vargas/9f1a14ac5f78d10eba56be437b7c76e5) - Setup instructions for using Factory CLI with Claude Code Max through CLIProxyAPI by [ben-vargas](ht",
    "url": "https://github.com/Factory-AI/factory/discussions/66",
    "timestamp": "2025-09-27T19:15:40Z",
    "metadata": {
      "type": "discussion",
      "category": "Show + tell",
      "number": 66
    }
  },
  {
    "id": "github_discussion_65",
    "source": "github",
    "author": "jimkyndemeyer",
    "content": "[Discussion] BYOK with Anthropic models on Amazon Bedrock\n\nWould be great to have the option of using Amazon Bedrock for Anthropic models with BYOK.\r\n\r\nAnthropic has official SDKs for Bedrock, but the model env config is a bit different:\r\n- AWS region\r\n- Access key id\r\n- Secret access key",
    "url": "https://github.com/Factory-AI/factory/discussions/65",
    "timestamp": "2025-09-27T09:46:55Z",
    "metadata": {
      "type": "discussion",
      "category": "Feature requests",
      "number": 65
    }
  },
  {
    "id": "github_discussion_59",
    "source": "github",
    "author": "factory-ben",
    "content": "[Discussion] #1 on Terminal Bench\n\n<img width=\"1582\" height=\"972\" alt=\"Screenshot 2025-09-25 at 17 15 56\" src=\"https://github.com/user-attachments/assets/9e9c80b6-825c-41cc-b8c7-236b21e3f61c\" />\r\n\r\nRead how we did it: https://factory.ai/news/terminal-bench",
    "url": "https://github.com/Factory-AI/factory/discussions/59",
    "timestamp": "2025-09-25T19:22:25Z",
    "metadata": {
      "type": "discussion",
      "category": "Factory Official",
      "number": 59
    }
  },
  {
    "id": "github_discussion_32",
    "source": "github",
    "author": "factory-ben",
    "content": "[Discussion] CLI v0.7.0 Release Notes\n\nCLI Release (0.7.0)\r\n\r\n- Autonomy level selection: Users can now select any preferred autonomy level when confirming the ExitSpec tool\r\n- Claude reasoning support: Added support for Claude's reasoning capabilities\r\n- Session resumption: Users can now resume existing sessions when operating in Exec Mode\r\n- Image reading capabilities: The CLI can now read and process images",
    "url": "https://github.com/Factory-AI/factory/discussions/32",
    "timestamp": "2025-09-19T20:15:48Z",
    "metadata": {
      "type": "discussion",
      "category": "Factory Official",
      "number": 32
    }
  },
  {
    "id": "github_discussion_25",
    "source": "github",
    "author": "DannyAziz",
    "content": "[Discussion] Change model even if I've already written a prompt out\n\nSometimes I write a message, then realise I want to drop down to Sonnet, and I have to delete my message to hit the slash command. I wish there was a way to do this without deleting everything.",
    "url": "https://github.com/Factory-AI/factory/discussions/25",
    "timestamp": "2025-09-16T22:58:36Z",
    "metadata": {
      "type": "discussion",
      "category": "Feature requests",
      "number": 25
    }
  }
]